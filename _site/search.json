[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "I was born, raised, and educated in Chile, and I currently live in Switzerland. I’m a Forest Engineer passionate about spatial analysis applied to landscape, conservation, and climate challenges.\nBefore studying Forest Engineering, I initially pursued a degree in Agronomy. At the core of my interests lies the deep interdependence between humans and nature, and the responsibility we have to manage it wisely.\n\n\n\nI work with GIS, remote sensing, and open environmental data to uncover insights and support sustainable solutions. In Chile, I have contributed to:\n\nRestoration projects\nBiological corridor design\nRiparian ecosystem assessment\n\nThese projects combine satellite imagery, environmental indicators, and hydrological data.\n\n\n\n\nI currently develop and document open workflows for spatial analysis using:\n\nPostGIS\nQGIS\nR\nPython\nQuarto"
  },
  {
    "objectID": "about.html#what-i-do",
    "href": "about.html#what-i-do",
    "title": "About Me",
    "section": "",
    "text": "I work with GIS, remote sensing, and open environmental data to uncover insights and support sustainable solutions. In Chile, I have contributed to:\n\nRestoration projects\nBiological corridor design\nRiparian ecosystem assessment\n\nThese projects combine satellite imagery, environmental indicators, and hydrological data."
  },
  {
    "objectID": "about.html#tools-skills",
    "href": "about.html#tools-skills",
    "title": "About Me",
    "section": "",
    "text": "I currently develop and document open workflows for spatial analysis using:\n\nPostGIS\nQGIS\nR\nPython\nQuarto"
  },
  {
    "objectID": "indicadores.html",
    "href": "indicadores.html",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "",
    "text": "The following workflow was developed as part of an academic residency for the undergraduate Forestry Engineering program under the supervision of Dr. Isabel Rojas.\nThis repository contains Python scripts designed to filter, organize, and prepare daily hydrometeorological data from the CAMELS-CL dataset for further analysis, such as with Climpact and Indicators of Hydrologic Alteration (IHA) tools. Climpact generates 33 climate indicators to assess climate change at each meteorological station. IHA (Indicators of Hydrologic Alteration) provides 33 indicators of hydrologic alteration and 34 indicators related to components of ecological flow, for each streamflow (hydrometric) station. This script allows for the systematic preparation of results from each station within a watershed into selected graphical figures.\nSome variable names and code comments are in Spanish as the original dataset and workflow were developed using Chilean climatic and hydrological data. However, all documentation, figures, and explanations are provided in English for international use. The code can be easily adapted to other languages or datasets. Variable names in Spanish follow the structure of the national dataset (Chile), but can be replaced as needed."
  },
  {
    "objectID": "indicadores.html#overview",
    "href": "indicadores.html#overview",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "1 Overview",
    "text": "1 Overview\nThe scripts perform the following main tasks:\n\nFilter CAMELS-CL data (tmax, tmin, precip, and q) for specific stations based on station codes\nCreate CSV files with year, month, and day columns plus values for each station.\nSplit data by station, saving individual files per station for each variable.\nFormat data for compatibility with Climpact and IHA:\n\n\nRemove NA and inf/-inf values.\nRemove column headers.\nFormat output into required directory structure.\n\n\nGenerate custom climate indicator figures from the output files generated by the Climpact tool.\nGenerate custom hydrologic indicator figures from the output files generated by the IHA tool."
  },
  {
    "objectID": "indicadores.html#how-to-use",
    "href": "indicadores.html#how-to-use",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "2 How to use",
    "text": "2 How to use\n\nClone this repository and open it in a Python-capable editor (recommended: Visual Studio Code).\nDownload here the working directory.\nRun the Preprocessing Data script.\nUse the generated products to import them into Climpact and IHA software.\nRun the script for automated generation of figures for climate and fluvial indicators"
  },
  {
    "objectID": "indicadores.html#indicators",
    "href": "indicadores.html#indicators",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "3 Indicators",
    "text": "3 Indicators\nIn the presentation of figures in this work, a selection of climatic and hydrological indicators was made based on their ability to assess climate change and their ecological relevance.\n\nClimatic indicators\n\n\nPrecipitation intensity (Figure 2)\nAnnual precipitation (Figure 3)\nConsecutive dry days (Figure 4)\nDays with precipitation &gt;= 30 mm (Figure 5)\nStandardised Precipitation Evapostranspiration Index (Figure 6)\nAnnual mean daily minimum temperature (Figure 7)\nAnnual mean daily maximum temperature (Figure 8)\nAnnual warmest daily maximum temperature (Figure 9)\nDays when minimum temperature &lt; 0ºC (Figure 10)\n\n\nStatistical analysis of flow rates\n\n\nFlow hydrograph (Figure 11)\nBoxplot of median monthly flow (Figure 12)\nPercentiles of monthly flow (Figure 13)\nFlow Duration Curve (Figure 14)\nMedian monthly flow of the entire basin (Figure 15)\n\n\nTime series of hydrological indicators\n\n\nMedian flow in July (Figure 16)\nHigh pulse duration (Figure 17)\nBase flow index (Figure 18)\nSmall flood peak (Figure 19)\nLarge flood peak (Figure 20)"
  },
  {
    "objectID": "indicadores.html#hydroclimatic-data-preprocessing-script",
    "href": "indicadores.html#hydroclimatic-data-preprocessing-script",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "4 Hydroclimatic Data Preprocessing Script",
    "text": "4 Hydroclimatic Data Preprocessing Script\n\n4.1 Filter CAMELS-CL data\n4.1.1. Dependencies and workspace\n4.1.1.1 Import libraries\n\n\nCode\nimport os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n\n4.1.1.2. Make sure the directory exists\n\n\nCode\ndef asegurar_directorio(ruta):\n    os.makedirs(ruta, exist_ok=True)\n\n\n4.1.1.3. Define folder paths\n\n\nCode\nruta_base = 'Hidroclima/Base de datos'\nruta_guardado = os.path.join(ruta_base, '0.filtrado_estaciones')\n\n\n4.1.1.4. Create the directory if it doesn’t exist\n\n\nCode\nasegurar_directorio(ruta_guardado)\n\n\n4.1.1.5. Additional columns\n\n\nCode\ncolumnas_adicionales = ['year', 'month', 'day']\n\n\n4.1.2. Maximum temperature filter 4.1.2.1. Read the CSV file\n\n\nCode\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmax_cr2met_C_day.csv'))\n\n\n4.1.2.2. Filter columns based on River Basin\n\n\nCode\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9100000 &lt;= int(col) &lt;= 9199999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\n\nIn this article, we will use the Toltén River Basin, Chile, identified by the code 94, as a case study.\nTo analyze a different basin:\n\nChange the station code range, for example, the Imperial River Basin, identified by the code 91.\nUpdate all relevant parts of the script accordingly.\n\n\n\nCode\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 &lt;= int(col) &lt;= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\n\n4.1.2.3. Create a new Data Frame with the filtered columns\n\n\nCode\ndf_filtrado = df[columnas_filtradas]\n\n\n4.1.2.4. Save the new Data Frame to a CSV file\n\n\nCode\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmax.csv'), index=False)\n\nprint(\"Filtered columns and new file of maximum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n\n\nFiltered columns and new file of maximum temperatures for the basin's stations saved.\nPreview:\n\n\n\n\nTable 1: Maximum temperature filter for the stations in each basin\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nmonth\nday\n1001001\n1001002\n1001003\n1020002\n1020003\n1021001\n\n\n\n\n0\n1979-01-01\n1979\n1\n1\n10.177674\n10.939560\n10.132287\n10.424700\n10.716425\n11.585810\n\n\n1\n1979-01-02\n1979\n1\n2\n10.073322\n10.855575\n9.982770\n10.489676\n10.810094\n11.818355\n\n\n2\n1979-01-03\n1979\n1\n3\n10.978896\n11.760256\n10.890517\n11.500134\n11.781082\n12.665569\n\n\n3\n1979-01-04\n1979\n1\n4\n8.506858\n9.651696\n8.612532\n8.862529\n9.321736\n10.355026\n\n\n4\n1979-01-05\n1979\n1\n5\n10.356481\n11.121019\n10.359378\n10.481868\n10.799477\n11.235866\n\n\n\n\n\n\n\n\n\n\n4.1.3. Minimum Temperature filter The same process is repeated as with the maximum temperature.\n\n\nCode\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmin_cr2met_C_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 &lt;= int(col) &lt;= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmin.csv'), index=False)\n\nprint(\"Filtered columns and new file of minimum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n\n\nFiltered columns and new file of minimum temperatures for the basin's stations saved.\nPreview:\n\n\n\n\nTable 2: Minimum temperature filter for the stations in each basin\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nmonth\nday\n1001001\n1001002\n1001003\n1020002\n1020003\n1021001\n\n\n\n\n0\n1979-01-01\n1979\n1\n1\n-5.849425\n-5.033302\n-5.138722\n-5.704229\n-5.709160\n-5.510278\n\n\n1\n1979-01-02\n1979\n1\n2\n-5.765660\n-4.986696\n-5.135554\n-5.446885\n-5.443863\n-5.084203\n\n\n2\n1979-01-03\n1979\n1\n3\n-5.718315\n-4.929108\n-5.020927\n-5.438698\n-5.442942\n-5.027288\n\n\n3\n1979-01-04\n1979\n1\n4\n-3.798310\n-2.945276\n-3.108570\n-4.030442\n-3.834039\n-3.309620\n\n\n4\n1979-01-05\n1979\n1\n5\n-4.913381\n-4.138040\n-4.194681\n-4.774841\n-4.826542\n-4.284366\n\n\n\n\n\n\n\n\n\n\n4.1.4. Precipitation filter The same process is repeated.\n\n\nCode\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/precip_cr2met_mm_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 &lt;= int(col) &lt;= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'pp.csv'), index=False)\n\nprint(\"Filtered columns and new file of precipitation for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n\n\nFiltered columns and new file of precipitation for the basin's stations saved.\nPreview:\n\n\n\n\nTable 3: Precipitation filter for the stations in each basin\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nmonth\nday\n1001001\n1001002\n1001003\n1020002\n1020003\n1021001\n\n\n\n\n0\n1979-01-01\n1979\n1\n1\n3.830792\n2.995933\n4.351452\n2.620128\n1.811431\n0.376418\n\n\n1\n1979-01-02\n1979\n1\n2\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n2\n1979-01-03\n1979\n1\n3\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.033105\n\n\n3\n1979-01-04\n1979\n1\n4\n2.855784\n2.070867\n2.963318\n3.065628\n2.160813\n1.676861\n\n\n4\n1979-01-05\n1979\n1\n5\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n\n\n\n\n\n\n\n\n\n\n4.1.5. Streamflow filter The same process is repeated.\n\n\nCode\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/q_m3s_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 &lt;= int(col) &lt;= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'q.csv'), index=False)\n\nprint(\"Filtered columns and new file of streamflow for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n\n\nFiltered columns and new file of streamflow for the basin's stations saved.\nPreview:\n\n\n\n\nTable 4: Streamflow filter for the stations in each basin\n\n\n\n\n\n\n\n\n\n\ndate\nyear\nmonth\nday\n1001001\n1001002\n1001003\n1020002\n1020003\n1021001\n\n\n\n\n0\n1900-01-01\n1900\n1\n1\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1900-01-02\n1900\n1\n2\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1900-01-03\n1900\n1\n3\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n1900-01-04\n1900\n1\n4\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n4\n1900-01-05\n1900\n1\n5\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n4.2 Create separate CSV files for each station and variable\n4.2.1. Minimum Temperature 4.2.1.1. CSV file path\n\n\nCode\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmin.csv'\n\n\n4.2.1.2. Read CSV file\n\n\nCode\ndf = pd.read_csv(archivo_csv)\n\n\n4.2.1.3. Get the Data Frame columns\n\n\nCode\ncolumnas = df.columns\n\n\n4.2.1.4. Create a directory to save files by column\n\n\nCode\noutput_dir = 'Hidroclima/Base de datos/1.temperaturas_min'\nos.makedirs(output_dir, exist_ok=True)\n\n\n4.2.1.5. Iterate over the columns and save the data for year, month, and day\n\n\nCode\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmin'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n    \nprint(\"Files of minimum temperature (tmin) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n\n\nFiles of minimum temperature (tmin) separated by station were successfully generated.\nGenerated_files:\n['9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9433001.csv\n\n\n\n\nTable 5: Daily minimum temperature for station 9437002\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ntmin\n\n\n\n\n0\n1979\n1\n1\n7.184061\n\n\n1\n1979\n1\n2\n6.857838\n\n\n2\n1979\n1\n3\n7.691808\n\n\n3\n1979\n1\n4\n7.785254\n\n\n4\n1979\n1\n5\n8.728067\n\n\n\n\n\n\n\n\n\n\n4.2.2. Maximum Temperature The same process is repeated\n\n\nCode\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmax.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/2.temperaturas_max'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmax'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of maximum temperature (tmax) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n\n\nFiles of maximum temperature (tmax) separated by station were successfully generated.\nGenerated_files:\n['9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9433001.csv\n\n\n\n\nTable 6: Daily maximum temperature for station 9437002\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\ntmax\n\n\n\n\n0\n1979\n1\n1\n23.202289\n\n\n1\n1979\n1\n2\n25.763368\n\n\n2\n1979\n1\n3\n25.706376\n\n\n3\n1979\n1\n4\n27.272382\n\n\n4\n1979\n1\n5\n27.402793\n\n\n\n\n\n\n\n\n\n\n4.2.3. Precipitation The same process is repeated\n\n\nCode\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/pp.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/3.precipitaciones'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'pp'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of precipitation (pp) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n\n\nFiles of precipitation (pp) separated by station were successfully generated.\nGenerated_files:\n['9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9433001.csv\n\n\n\n\nTable 7: Daily precipitation for station 9437002\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\npp\n\n\n\n\n0\n1979\n1\n1\n0.0\n\n\n1\n1979\n1\n2\n0.0\n\n\n2\n1979\n1\n3\n0.0\n\n\n3\n1979\n1\n4\n0.0\n\n\n4\n1979\n1\n5\n0.0\n\n\n\n\n\n\n\n\n\n\n4.2.4. Streamflow The same process is repeated\n\n\nCode\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/q.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/7.caudales'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'q'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of streamflow (q) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n\n\nFiles of streamflow (q) separated by station were successfully generated.\nGenerated_files:\n['9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9433001.csv\n\n\n\n\nTable 8: Daily streamflow for station 9437002\n\n\n\n\n\n\n\n\n\n\nyear\nmonth\nday\nq\n\n\n\n\n0\n1900\n1\n1\nNaN\n\n\n1\n1900\n1\n2\nNaN\n\n\n2\n1900\n1\n3\nNaN\n\n\n3\n1900\n1\n4\nNaN\n\n\n4\n1900\n1\n5\nNaN\n\n\n\n\n\n\n\n\n\n\n\n\n4.3 Split data by station\n4.3.1. Format data for compability with Climpact 4.3.1.1. Mapping precipitation, minimum and maximum temperature based on filename and file path\n\n\nCode\ndir_principal = 'Hidroclima/Base de datos'\n\nsubcarpetas = ['1.temperaturas_min', '2.temperaturas_max', '3.precipitaciones']\n\ncolumna_map = {\n    '1.temperaturas_min': 'tmin',\n    '2.temperaturas_max': 'tmax',\n    '3.precipitaciones': 'prcp'\n}\n\ndef obtener_archivos(subcarpeta):\n    ruta_subcarpeta = os.path.join(dir_principal, subcarpeta)\n    archivos = [archivo for archivo in os.listdir(ruta_subcarpeta) if archivo.endswith('.csv') and archivo not in ['year.csv', 'month.csv', 'day.csv']]\n    return archivos\n\ndef leer_archivo(ruta, columna):\n    df = pd.read_csv(ruta)\n    df = df.rename(columns={df.columns[-1]: columna})\n    return df\n\nestaciones_data = {}\n\nfor subcarpeta in subcarpetas:\n    columna = columna_map[subcarpeta]\n    archivos = obtener_archivos(subcarpeta)\n    \n    for archivo in archivos:\n        estacion = os.path.splitext(archivo)[0]\n        ruta_archivo = os.path.join(dir_principal, subcarpeta, archivo)\n        \n        df = leer_archivo(ruta_archivo, columna)\n        \n        if estacion not in estaciones_data:\n            estaciones_data[estacion] = df[['year', 'month', 'day', columna]]\n        else:\n            estaciones_data[estacion] = estaciones_data[estacion].merge(df[['year', 'month', 'day', columna]], on=['year', 'month', 'day'], how='outer')\n\n\n4.3.1.2. Save files by station\n\n\nCode\noutput_dir = os.path.join(dir_principal, '4.pre_Climpact')\nos.makedirs(output_dir, exist_ok=True)\n\nfor estacion, df in estaciones_data.items():\n    for columna in ['prcp', 'tmax', 'tmin']:\n        if columna not in df.columns:\n            df[columna] = pd.NA\n    \n    df = df[['year', 'month', 'day', 'prcp', 'tmax', 'tmin']]\n\n\n4.3.1.3. Format:\n\nApproximate variable values to 1 decimal place\nConvert dayand month values to 2 digits\nCombine year, month and day into a single ‘date’ column\nReplace inf, -inf and NaN values ​​with -99.9\nExport as a .txt file\nCorrect order of columns\n\n\n\nCode\n    df[['prcp', 'tmax', 'tmin']] = df[['prcp', 'tmax', 'tmin']].apply(lambda x: round(x, 1))\n    \n    df['month'] = df['month'].apply(lambda x: f'{x:02}')\n    df['day'] = df['day'].apply(lambda x: f'{x:02}')\n    \n    df['fecha'] = df.apply(lambda row: f\"{int(row['year']):4d} {row['month']} {row['day']}\", axis=1)\n    \n    df = df.replace([float('inf'), float('-inf')], -99.9).fillna(-99.9)\n    \n    ruta_salida = os.path.join(output_dir, f'{estacion}.txt')\n    \n    with open(ruta_salida, 'w') as f:\n        for _, row in df.iterrows():\n            f.write(f\"{row['fecha']}    {row['prcp']:5.1f}     {row['tmax']:4.1f}     {row['tmin']:4.1f}\\n\")\n\nprint(\"Files for Climpact generated successfully.\")\n\narchivos_generados = sorted(os.listdir(output_dir))\ndf_archivos = pd.DataFrame(archivos_generados, columns=['Generated files'])\ndisplay(df_archivos)\n\n\nFiles for Climpact generated successfully.\n\n\n\n\nTable 9: List of the generated files in the output directory\n\n\n\n\n\n\n\n\n\n\nGenerated files\n\n\n\n\n0\n9414001.txt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 10: Station 9437002 file with information on each variable\n\n\n\n\n\n\n1900\n1\n1\nNaN\n\n\n1900\n1\n2\nNaN\n\n\n1900\n1\n3\nNaN\n\n\n1900\n1\n4\nNaN\n\n\n1900\n1\n5\nNaN\n\n\n\n\n\n\n\n\n4.3.2. Format data for compability with IHA 4.3.2.1. The same process is repeated, now for the streamflow.\n\n\nCode\ndir_entrada = os.path.join('Hidroclima', 'Base de datos', '7.caudales')\ndir_salida = os.path.join('Hidroclima', 'Base de datos', '8.pre_IHA')\n\nos.makedirs(dir_salida, exist_ok=True)\n\nfor archivo in os.listdir(dir_entrada):\n    if archivo.endswith('.csv'):\n        ruta_entrada = os.path.join(dir_entrada, archivo)\n        \n        archivo_salida = os.path.splitext(archivo)[0] + '.txt'\n        ruta_salida = os.path.join(dir_salida, archivo_salida)\n\n        df = pd.read_csv(ruta_entrada)\n\n        columnas_requeridas = {'year', 'month', 'day', 'q'}\n        if not columnas_requeridas.issubset(df.columns):\n            print(f\"The {archivo} file does not contain the required columns: {columnas_requeridas}\")\n            continue\n\n        df = df[['year', 'month', 'day', 'q']]\n\n\nThe year.csv file does not contain the required columns: {'year', 'day', 'month', 'q'}\nThe month.csv file does not contain the required columns: {'year', 'day', 'month', 'q'}\nThe day.csv file does not contain the required columns: {'year', 'day', 'month', 'q'}\n\n\n4.3.2.2. Format:\n\nAproximate streamflow values to 1 decimal place\nDate column in YYYY-MM-DD format\nReplace inf, -inf, and NaN values ​​with -1.0\nDelete leading rows where ‘q’ equals -1.0\nStreamflow column named flow\nExport as .txtfile\n\n\n\nCode\n        df = df.replace([float('inf'), float('-inf')], -1.0).fillna(-1.0)\n\n        df = df.loc[df['q'] != -1.0].reset_index(drop=True)\n\n        df['q'] = df['q'].round(1)\n\n        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n        df = df[['date', 'q']].rename(columns={'q': 'flow'})\n\n        df.to_csv(ruta_salida, index=False, header=True)\n\nprint(\"IHA files processed successfully.\")\n\n\nIHA files processed successfully.\n\n\n\n\n4.4 Extra files and folders for sorting results\n4.4.1. List of folders to create:\n\nFolder 5 stores the station-specific folders generated by Climpact.\nFolder 6 contains customized plots based on Climpact results.\nFolder 9 stores the Excel files generated by IHA for each station, along with their processed CSV versions.\nFolder 10 includes the figures created from IHA data.\nFolder 11 contains text files intended to be imported into QGIS for georeferencing.\n\n\n\nCode\nruta_base = os.path.join('Hidroclima', 'Base de datos')\n\ncarpetas = [\n    '5.Climpact',\n    '6.Figuras_Climpact',\n    '9.IHA',\n    '10.Figuras_IHA',\n    '11.Georreferenciación'\n]\n\nfor carpeta in carpetas:\n    ruta_carpeta = os.path.join(ruta_base, carpeta)\n    os.makedirs(ruta_carpeta, exist_ok=True)\n    print(f\"Folder created: {ruta_carpeta}\")\n\nprint(\"All necessary folders for the results have been created successfully.\")\n\n\nFolder created: Hidroclima/Base de datos/5.Climpact\nFolder created: Hidroclima/Base de datos/6.Figuras_Climpact\nFolder created: Hidroclima/Base de datos/9.IHA\nFolder created: Hidroclima/Base de datos/10.Figuras_IHA\nFolder created: Hidroclima/Base de datos/11.Georreferenciación\nAll necessary folders for the results have been created successfully.\n\n\n4.4.2. Georeference the stations in the study basin\n\n\nCode\narchivo_entrada = \"Hidroclima/Base de datos/CAMELS_CL_v202201/catchment_attributes.csv\"\ndf = pd.read_csv(archivo_entrada)\n\ndf_filtrado = df[(df['gauge_id'] &gt;= 9400000) & (df['gauge_id'] &lt;= 9499999)]\n\ndf_filtrado = df_filtrado[['gauge_id', 'gauge_name', 'gauge_lat', 'gauge_lon', 'record_period_start', 'record_period_end']]\n\ndirectorio_salida = \"Hidroclima/Base de datos/11.Georreferenciación/Estaciones.csv\"\n\ndf_filtrado.to_csv(directorio_salida, index=False)\n\nprint(\"Filtered file saved as:\", directorio_salida)\n\nfrom IPython.display import display\ndisplay(df_filtrado)\n\n\nFiltered file saved as: Hidroclima/Base de datos/11.Georreferenciación/Estaciones.csv\n\n\n\n\nTable 11: Information by georeferenced station\n\n\n\n\n\n\n\n\n\n\ngauge_id\ngauge_name\ngauge_lat\ngauge_lon\nrecord_period_start\nrecord_period_end\n\n\n\n\n370\n9400000\nRio Truful En Camino Internacional\n-38.8444\n-71.6536\n2014-12-18\n2020-03-24\n\n\n371\n9402001\nRio Allipen En Melipeuco\n-38.8653\n-71.7336\n1985-01-17\n2019-08-31\n\n\n372\n9404001\nRio Allipen En Los Laureles\n-38.9833\n-72.2333\n1946-03-18\n2019-11-10\n\n\n373\n9405001\nRio Curaco En Colico\n-39.0333\n-72.0833\n1986-10-31\n2019-03-27\n\n\n374\n9412001\nRio Trancura En Curarrehue\n-39.3600\n-71.5808\n1968-09-01\n2020-04-07\n\n\n375\n9414001\nRio Trancura Antes Rio Llafenco\n-39.3333\n-71.7667\n1970-10-01\n2019-08-31\n\n\n376\n9416001\nRio Liucura En Liucura\n-39.2561\n-71.8244\n1971-10-01\n2019-04-29\n\n\n377\n9420001\nRio Tolten En Villarica\n-39.2667\n-72.2333\n1929-03-05\n2020-03-01\n\n\n378\n9423001\nRio Tolten En Coipue\n-39.1000\n-72.3833\n1929-12-16\n2020-03-25\n\n\n379\n9433001\nRio Puyehue En Quitratue\n-39.1500\n-72.6667\n1947-10-07\n2019-08-31\n\n\n380\n9434001\nRio Donguil En Gorbea\n-39.1000\n-72.6833\n1947-10-06\n2019-08-31\n\n\n381\n9436001\nRio Mahuidanche En Santa Ana\n-39.0833\n-72.9333\n1987-03-17\n2019-04-30\n\n\n382\n9437002\nRio Tolten En Teodoro Schmidt\n-39.0144\n-73.0828\n1991-02-12\n2020-04-07"
  },
  {
    "objectID": "indicadores.html#generation-of-figures-for-climate-indicators-script",
    "href": "indicadores.html#generation-of-figures-for-climate-indicators-script",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "5 Generation of figures for climate indicators script",
    "text": "5 Generation of figures for climate indicators script\nBy default, Climpact generates figures for each calculated indicator at each station. However, the following script provides a general framework for creating customized figures.\n\n5.1 General framework for customized figures\n5.1.1. Libraries.\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom scipy.stats import linregress\n\n\n5.1.2. Base route and output route.\nIn this case, the figure of the annual accumulated precipitation indicator is generated.\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n\n5.1.3. Selecting the indicator to be graphed.\nIn this case, the annual total precipitation indicator is used, identified as prcptot in the dataset and therefore with its corresponding station code followed by _prcptot_ANN.csv in its file name. To select a different indicator, simply use the name of the corresponding file that contains the desired variable, for example, _txx_ANN.csv and the txx variable for monthly maximum daily temperature.\n\n\nCode\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n\n\n5.1.4. Create the figure.\nThe use of Sen’s slope, the regression line, and the statistical values calculated by the Climpact software have not yet been systematically included in the figure.\n\n\nCode\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Annual precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n        \n        contador += 1\n\n\n\n\n\n\n\n\nFigure 1: Indicator of total accumulated precipitation at station 9434001\n\n\n\n\n\n\n\n5.2 Suggested precipitation indicators and their figures\n5.2.1. Precipitation intensity (sdii).\nAnnual total precipitation divided by the number of wet days (when total precipitation &gt;= 1.0 mm) is now graphed for each station.\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_sdii_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'sdii']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['sdii'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['sdii'], marker='D', linestyle='-', color='black', label='Precipitation intensity')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['sdii'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation intensity\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_sdii_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 2: Indicator of precipitation intensity at station 9423001\n\n\n\n\n\n5.2.2. Anual accumulated precipitation (prcptot).\nAnnual sum of daily precipitation &gt;= 1.0 mm is now graphed for each station. This was already calculated above.\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Total Precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Anual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 3: Indicator of total accumulated precipitation at station 9423001\n\n\n\n\n\n5.2.3. Consecutive dry days (cdd).\nMaximum annual number of consecutive dry days (when precipitation &lt; 1.0 mm).\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_cdd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'cdd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['cdd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['cdd'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['cdd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Consecutive dry days\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_cdd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 4: Indicator of consecutive dry days at station 9423001\n\n\n\n\n\n5.2.4. Days with precipitation greater than 30mm (r30mm).\nNumber of days when precipitation &gt;= 30mm.\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_r30mm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'r30mm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['r30mm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['r30mm'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['r30mm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation &gt;= 30mm\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_r30mm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 5: Indicator of days with precipitation greater than 30 mm at station 9423001\n\n\n\n\n\n5.2.5. Standardised Precipitation Evapotranspiration Index (SPEI)\nThis indicator estimates water balance using precipitation and temperature information. It provides a drought indicator. In this case, it is graphed on a 24-month scale. Due to the monthly scale of the indicator, the code has slight adjustments.\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_24month_spei_MON.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'spei']]\n\n        df['time'] = pd.to_datetime(df['time'], format='%Y-%m')\n\n        df = df[df['spei'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n\n        df_pos = df[df['spei'] &gt;= 0]\n        df_neg = df[df['spei'] &lt; 0]\n\n        plt.plot(df.index, df['spei'], linestyle='-', color='black', label='SPEI')\n\n        plt.plot(df_pos.index, df_pos['spei'], marker='o', linestyle='None', color='black', label='SPEI ≥ 0')\n\n        plt.plot(df_neg.index, df_neg['spei'], marker='o', linestyle='None', color='gray', label='SPEI &lt; 0')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['spei'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - SPEI compared to the last 24 months\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('SPEI', fontsize=24, fontname='Times New Roman')\n\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_spei24_MON_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 6: Indicator of Standardised Precipitation Evapotrasnpiration Index at station 9423001\n\n\n\n\n\n\n\n5.3 Suggested temperature indicators and their figures\n5.3.1. Annual mean daily minimum temperature (tnm).\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_tnm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'tnm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['tnm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['tnm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['tnm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily minimum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_tnm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 7: Indicator of annual mean daily minimum temperature at station 9423001\n\n\n\n\n\n5.3.2. Annual mean daily maximum temperature (txm).\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 8: Indicator of annual mean daily maximum temperature at station 9423001\n\n\n\n\n\n5.3.3. Annual warmest daily maximum temperature (txx).\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txx_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txx']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txx'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txx'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txx'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual warmest daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txx_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 9: Indicator of annual warmest daily maximum temperature at station 9423001\n\n\n\n\n\n5.3.4. Annual number of days when minimum temperature &lt; 0ºC (id).\n\n\nCode\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_fd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'fd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['fd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['fd'], marker='D', linestyle='-', color='black', label='Days T&lt;0ºC')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['fd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Days when minimum temperature &lt; 0ºC\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_fd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n\n\n\n\n\n\n\n\nFigure 10: Indicator of annual numbery of days when minimum temperature is lower than 0ºC at station 9423001"
  },
  {
    "objectID": "indicadores.html#generation-of-figures-for-hydrologic-indicators-script",
    "href": "indicadores.html#generation-of-figures-for-hydrologic-indicators-script",
    "title": "Automated generation of hydroclimatic indicators",
    "section": "6 Generation of figures for hydrologic indicators script",
    "text": "6 Generation of figures for hydrologic indicators script\n\n6.1 Libraries and workspace.\n\n\nCode\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport matplotlib.pyplot as plt\n\ninput_directory = 'Hidroclima/Base de datos/9.IHA'\n\nsheets_to_convert = ['ann', 'sco', 'lsq', 'pct', 'daily efcs', 'fdc']\n\nfor filename in os.listdir(input_directory):\n    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n        filepath = os.path.join(input_directory, filename)\n        excel_file = pd.ExcelFile(filepath)\n        \n        station_code = os.path.splitext(filename)[0]\n        \n        station_output_directory = os.path.join(input_directory, 'csv', station_code)\n        \n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for sheet in sheets_to_convert:\n            if sheet in excel_file.sheet_names:\n                df = pd.read_excel(filepath, sheet_name=sheet)\n                \n                output_filename = f\"{sheet}_{station_code}.csv\"\n                output_filepath = os.path.join(station_output_directory, output_filename)\n                \n                df.to_csv(output_filepath, index=False)\n                \nprint(\"ann, sco, fdc, pct, lsq and daily efcs files saved in its folder.\")\n\n\nann, sco, fdc, pct, lsq and daily efcs files saved in its folder.\n\n\n\n\n6.2 Streamflow figures\n6.2.1. Simple monthly median flow for each station\nThe order of the months in the sco_ file may vary. If so, adjust the meses_ingles variable accordingly.\n\n\nCode\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\n\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\nmeses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n\n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            plt.figure(figsize=(12, 8))\n            plt.plot(df_mes.index, df_mes['Median'], marker='.', linestyle='-', color='black', label='Median')\n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Median monthly flow - {station_code} Station', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.grid(True, linestyle='-', linewidth=0.5, color='lightgray')\n            plt.legend(fontsize=14)\n            plt.grid(False)\n\n            output_file = os.path.join(output_dir, f'Median_monthly_flow_{station_code}.png')\n            plt.tight_layout()\n            plt.savefig(output_file, dpi=300)\n            \n            plt.savefig(ruta_salida)\n\n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n\n            contador += 1\n            print(f'Figure saved: {output_file}')\n\n\n\n\n\n\n\n\nFigure 11: Indicator of simple monthly median flow at station 9423001\n\n\n\n\n\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9423001/Median_monthly_flow_9423001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9433001/Median_monthly_flow_9433001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9434001/Median_monthly_flow_9434001.png\n\n\n6.2.2. Boxplot flow for each month calculated from all recorded years for each station\nThe language of the months or even the way they are written in the ann_ file may vary. If so, adjust the columns variable and id_vars accordingly.\n\n\nCode\nbase_directory = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = os.path.join('Hidroclima/Base de datos/10.Figuras_IHA', 'Caudal')\nif not os.path.exists(output_root_directory):\n    os.makedirs(output_root_directory)\n\ncontador = 0\n\nfor station_folder in os.listdir(base_directory):\n    station_path = os.path.join(base_directory, station_folder)\n    if os.path.isdir(station_path):\n        station_output_directory = os.path.join(output_root_directory, station_folder)\n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for filename in os.listdir(station_path):\n            if filename.startswith('ann_') and filename.endswith('.csv'):\n                input_file = os.path.join(station_path, filename)\n                \n                df = pd.read_csv(input_file, skiprows=4)\n                \n                columns = ['Year', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n                df = df[columns]\n\n                df_melted = df.melt(id_vars=['Year'], var_name='Month', value_name='Value')\n                \n                month_translation = {\n                    'January': 'January', 'February': 'February', 'March': 'March', 'April': 'April', \n                    'May': 'May', 'June': 'June', 'July': 'July', 'August': 'August', \n                    'September': 'September', 'October': 'October', 'November': 'November', \n                    'December': 'December'\n                }\n\n                df_melted['Month'] = df_melted['Month'].map(month_translation)\n                \n                plt.rcParams[\"font.family\"] = \"Times New Roman\"\n                plt.rcParams[\"font.size\"] = 12\n                plt.rcParams[\"axes.titlesize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"axes.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"xtick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"ytick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                \n                plt.figure(figsize=(12, 6))\n                sns.boxplot(\n                    x='Month', y='Value', data=df_melted,\n                    order=['January', 'February', 'March', 'April', 'May', 'June', 'July', \n                           'August', 'September', 'October', 'November', 'December'],\n                    color='gray'\n                )\n                #plt.title(f'Distribution of the median monthly flow - {station_folder} Station')\n                plt.xlabel('Month')\n                plt.ylabel('Flow (m3/s)')\n                plt.xticks(rotation=45)\n                plt.tight_layout()\n                \n                output_plot_path = os.path.join(station_output_directory, f'BOXPLOT_{filename[:-4]}.png')\n                plt.savefig(output_plot_path, dpi=300)\n                \n                if contador == 0:\n                    plt.show()\n                else:\n                    plt.close()\n\n                contador += 1\n                \n                print(f'Boxplot saved: {output_plot_path}')\n\n\n\n\n\n\n\n\nFigure 12: Boxplot of flow at station 9423001\n\n\n\n\n\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9423001/BOXPLOT_ann_9423001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9433001/BOXPLOT_ann_9433001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9434001/BOXPLOT_ann_9434001.png\n\n\n6.2.3. Figure with the percentiles of monthly flows for all years evaluated by station.\nThe order of the months in the pct_ file may vary. If so, adjust the meses_ingles variable accordingly.\n\n\nCode\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"pct_\") and file.endswith(\".csv\"):\n            pct_file = os.path.join(root, file)\n            \n            station_code = os.path.basename(root)\n            \n            station_output_directory = os.path.join(output_root_directory, station_code)\n            \n            if not os.path.exists(station_output_directory):\n                print(f\"Error: The output directory for station {station_code} does not exist.\")\n                continue\n            \n            df = pd.read_csv(pct_file, skiprows=8, header=None) \n            df_mes = df.iloc[:12, :6]\n            df_mes.columns = ['Month', '10%', '25%', '50%', '75%', '90%']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            \n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            plt.figure(figsize=(12, 8))\n            linestyles = ['-', '--', '-.', ':', (0, (1, 10))]\n            marcadores = ['o', 's', '^', 'D', '*']\n            \n            for percentil, linestyle, marcador in zip(['10%', '25%', '50%', '75%', '90%'], linestyles, marcadores):\n                plt.plot(df_mes.index, df_mes[percentil], marker=marcador, linestyle=linestyle, label=percentil, color='black')\n            \n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Percentiles of monthly flows for {station_code}', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14)\n            plt.grid(False)\n            plt.tight_layout()\n            \n            output_plot_path = os.path.join(station_output_directory, f'percentiles_{station_code}.png')\n            plt.savefig(output_plot_path, dpi=300)\n            \n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n            \n            contador += 1\n            \n            print(f'Figure saved: {output_plot_path}')\n\n\n\n\n\n\n\n\nFigure 13: Percentiles of monthly flows at station 9423001\n\n\n\n\n\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9423001/percentiles_9423001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9433001/percentiles_9433001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9434001/percentiles_9434001.png\n\n\n6.2.4. Graphs for each station with the probability of exceedance for each month and at an annual level.\nThe language of the months or even the way they are written in the fdc_ file may vary. If so, adjust the meses variable accordingly.\n\n\nCode\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nmeses = {\n    'Annual': 'Annual', 'January': 'January', 'February': 'February', 'March': 'March',\n    'April': 'April', 'May': 'May', 'June': 'June', 'July': 'July', \n    'August': 'August', 'September': 'September', 'October': 'October', \n    'November': 'November', 'December': 'December'\n}\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"fdc_\") and file.endswith(\".csv\"):\n            fdc_file = os.path.join(root, file)\n            \n            df_headers = pd.read_csv(fdc_file, skiprows=9, nrows=1, header=None)\n            df_data = pd.read_csv(fdc_file, skiprows=11, header=None)\n            \n            col_indices = {}\n            for col_idx, col_name in enumerate(df_headers.iloc[0]):\n                if isinstance(col_name, str) and col_name.strip() in meses:\n                    col_indices[meses[col_name.strip()]] = col_idx\n            \n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            for mes, mes_label in meses.items():\n                if mes_label in col_indices:\n                    x_col = col_indices[mes_label] + 1\n                    y_col = col_indices[mes_label] \n\n                    data = df_data.iloc[:, [y_col, x_col]].dropna()\n                    data.columns = ['Caudal', 'Probabilidad']\n                    data['Probabilidad'] = data['Probabilidad']\n                    \n                    plt.figure(figsize=(12, 8))\n                    plt.plot(data['Probabilidad'], data['Caudal'], marker='o', linestyle='-', color='black')\n                    #plt.title(f'Flow Duration Curve - {mes_label} ({station_code})', fontsize=16, fontname='Times New Roman')\n                    plt.xlabel('Probability of Exceedance (%)', fontsize=14, fontname='Times New Roman')\n                    plt.ylabel('Flow (m³/s)', fontsize=14, fontname='Times New Roman')\n                    plt.grid(False)\n                    plt.tight_layout()\n                    \n                    output_file = os.path.join(output_dir, f'FDC_{mes_label}_{station_code}.png')\n                    plt.savefig(output_file, dpi=300)\n                    \n                    if contador == 1:\n                        plt.show()\n                    else:\n                        plt.close()\n                        \n                    contador += 1\n                    \nprint('Flow Duration Curve generated for each month of each station')\n\n\n\n\n\n\n\n\nFigure 14: Flow Duration Curve for January at station 9423001\n\n\n\n\n\nFlow Duration Curve generated for each month of each station\n\n\n6.2.5. Figure of the streamflow of all stations present in the basin\nThe order of the months in the sco_ file may vary. If so, adjust the meses_ingles variable accordingly.\n\n\nCode\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\nsave_path = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\nos.makedirs(save_path, exist_ok=True)\n\nlinestyles = ['-', '--', '-.', ':', (0, (1, 10)), (0, (5, 10)), (0, (3, 5)), (0, (3, 1)), (0, (5, 3)), (0, (1, 1)), (0, (5, 1)), (0, (1, 5))]\ncolores = ['black', 'darkgray', 'gray', 'lightgray', 'black', 'dimgray', 'gray', 'dimgray', 'darkgray', 'black', 'dimgray', 'black']\nplt.figure(figsize=(12, 8))\nline_counter = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            nombre_archivo = os.path.basename(sco_file)\n            codigo_estacion = nombre_archivo.split('_')[1].split('.')[0]\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            linestyle = linestyles[line_counter % len(linestyles)]\n            color = colores[line_counter % len(colores)]\n            plt.plot(df_mes.index, df_mes['Median'], linestyle=linestyle, color=color, label=f'Station {codigo_estacion}')\n            line_counter += 1\n\nplt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n#plt.title('Median monthly flow by station', fontsize=24, fontname='Times New Roman')\nplt.xlabel('Month', fontsize=24, fontname='Times New Roman')\nplt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\nplt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\nplt.yticks(fontsize=24, fontname='Times New Roman')\nplt.grid(True, linestyle='-', linewidth=0.5, color='black')\nplt.legend(fontsize=14)\nplt.grid(False)\n\nsave_file = os.path.join(save_path, 'qmonthly_TOTstations.png')\nplt.tight_layout()\nplt.savefig(save_file, dpi=300)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 15: Median monthly flow by station\n\n\n\n\n\n\n\n6.3 Time series figures\nThe language of the months, indicator and column of “year” or even the way they are written in the ann_ and sco_ file may vary.\nIf so, adjust:\n\nindicator_names variable\nthe names for the regression in row lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\nthe skiprows variable in sco_data with the number of the row where the list of the respective indicator begins\nthe slope, intercept and r_squared variables\n\n6.3.1. Median flow in July over time.\nIn this case, the time series of the median flow in July was selected, as it corresponds to the month with the highest flow in the study basin.\n6.3.1.1. Reading input files and extracting specific data related to the selected month.\n\n\nCode\nbase_folder_path = 'Hidroclima/Base de datos/9.IHA/csv/'\noutput_folder_path = 'Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/'\nos.makedirs(output_folder_path, exist_ok=True)\n\nindicator_names = {\n    'lsq_row': 'July',              \n    'ann_column': 'July',           \n    'sco_row': 'July',              \n    'plot_label': 'July'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=17, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\n\n6.3.1.2. Saving the extracted data in a single .csv file.\n\n\nCode\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\n\n6.3.1.3. Graph format.\n\n\nCode\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV file and figure for station {station_code} has been saved in {graph_filename}\")\n\n\n6.3.1.4. Graph generation.\n\n\nCode\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n\n\nThe CSV file and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/july_9423001.png\n\n\n\n\n\n\n\n\nFigure 16: Median flow in July over time at station 9423001\n\n\n\n\n\nThe CSV file and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/july_9433001.png\nThe CSV file and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/july_9434001.png\n\n\n6.3.2. High flow pulses duration by station\n6.3.2.1. Reading input files and extracting specific data related to the selected indicator.\n\n\nCode\nindicator_names = {\n    'lsq_row': 'High pulse duration',              \n    'ann_column': 'Hi pulse L',           \n    'sco_row': 'High pulse duration',              \n    'plot_label': 'High pulse duration'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=48, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\n\n6.3.2.2. Saving the extracted data in a single .csv file.\n\n\nCode\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\n\n6.3.2.3. Graph format.\n\n\nCode\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\n\n6.3.2.4. Graph generation.\n\n\nCode\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n\n\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/high_pulse_duration_9423001.png\n\n\n\n\n\n\n\n\nFigure 17: High flow pulses duration over time at station 9423001\n\n\n\n\n\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/high_pulse_duration_9433001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/high_pulse_duration_9434001.png\n\n\n6.3.3. Base Flow Index by station\n6.3.3.1. Reading input files and extracting specific data related to the selected indicator.\n\n\nCode\nindicator_names = {\n    'lsq_row': 'Base flow index',              \n    'ann_column': 'Base flow',           \n    'sco_row': 'Base flow index',              \n    'plot_label': 'Base flow index'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=30, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\n\n6.3.3.2. Saving the extracted data in a single .csv file.\n\n\nCode\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\n\n6.3.3.3. Graph format.\n\n\nCode\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('BFI', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\n\n6.3.3.4. Graph generation.\n\n\nCode\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n\n\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/base_flow_index_9423001.png\n\n\n\n\n\n\n\n\nFigure 18: Base Flow Index over time at station 9423001\n\n\n\n\n\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/base_flow_index_9433001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/base_flow_index_9434001.png\n\n\n6.3.4. Small Floods Peaks over time\nThe same process is repeated, adjusted to the specific indicator.\n\n\nCode\nindicator_names = {\n    'lsq_row': 'Small Flood peak',              \n    'ann_column': 'Sfld1 peak',           \n    'sco_row': 'Small Flood peak',              \n    'plot_label': 'Small Flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=80, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n\n\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/small_flood_peak_9423001.png\n\n\n\n\n\n\n\n\nFigure 19: Small Floods Peaks over time at station 9423001\n\n\n\n\n\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/small_flood_peak_9433001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/small_flood_peak_9434001.png\n\n\n6.3.4. Large Floods Peaks over time\nThe same process is repeated, adjusted to the specific indicator.\n\n\nCode\nindicator_names = {\n    'lsq_row': 'Large flood peak',              \n    'ann_column': 'Lfld1 peak',           \n    'sco_row': 'Large flood peak',              \n    'plot_label': 'Large flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=85, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 2:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n\n\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/large_flood_peak_9423001.png\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/large_flood_peak_9433001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/large_flood_peak_9434001.png\n\n\n\n\n\n\n\n\nFigure 20: Large Floods Peaks over time at station 9423001"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Andrea Redel",
    "section": "",
    "text": "Here I present various visualizations, analyses, documentation, and methodologies related to landscape and forest analysis for the study of conservation and climate change.\nThis project is under continuous development. You can check out the source code on my GitHub."
  },
  {
    "objectID": "index.html#welcome-to-my-site-on-conservation-landscape-and-climate-change",
    "href": "index.html#welcome-to-my-site-on-conservation-landscape-and-climate-change",
    "title": "Andrea Redel",
    "section": "",
    "text": "Here I present various visualizations, analyses, documentation, and methodologies related to landscape and forest analysis for the study of conservation and climate change.\nThis project is under continuous development. You can check out the source code on my GitHub."
  },
  {
    "objectID": "index.html#some-of-my-projects",
    "href": "index.html#some-of-my-projects",
    "title": "Andrea Redel",
    "section": "Some of my projects:",
    "text": "Some of my projects:\n\nHydroclimatic Indicator Workflow\nMore projects coming soon"
  }
]