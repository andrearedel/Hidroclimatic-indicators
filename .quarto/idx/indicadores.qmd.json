{"title":"Automated generation of hydroclimatic indicators","markdown":{"yaml":{"title":"Automated generation of hydroclimatic indicators","author":"Andrea Redel","format":{"html":{"code-fold":true,"toc":true,"number-sections":true,"theme":"sandstone","code-tools":true},"pdf":"default"},"editor":"visual","jupyter":"python3"},"headingText":"Overview","containsRefs":false,"markdown":"\n\nThe following workflow was developed as part of an academic residency for the undergraduate Forestry Engineering program under the supervision of Dr. Isabel Rojas.\n\nThis repository contains Python scripts designed to filter, organize, and prepare daily hydrometeorological data from the *CAMELS-CL* dataset for further analysis, such as with *Climpact* and *Indicators of Hydrologic Alteration (IHA)* tools. Climpact generates **33 climate indicators** to assess climate change at each meteorological station. IHA (Indicators of Hydrologic Alteration) provides **33 indicators of hydrologic alteration** and **34 indicators related to components of ecological flow**, for each streamflow (hydrometric) station. This script allows for the **systematic preparation of results** from each station within a watershed into selected graphical figures.\n\nSome variable names and code comments are in Spanish as the original dataset and workflow were developed using Chilean climatic and hydrological data. However, all documentation, figures, and explanations are provided in English for international use. The code can be easily adapted to other languages or datasets. Variable names in Spanish follow the structure of the national dataset (Chile), but can be replaced as needed.\n\n\nThe scripts perform the following main tasks:\n\n1.  **Filter CAMELS-CL data** (`tmax`, `tmin`, `precip`, and `q`) for specific stations based on station codes\n\n2.  **Create CSV files** with `year`, `month`, and `day` columns plus values for each station.\n\n3.  **Split data by station**, saving individual files per station for each variable.\n\n4.  **Format data** for compatibility with Climpact and IHA:\n\n-   Remove `NA` and `inf`/`-inf` values.\n\n-   Remove column headers.\n\n-   Format output into required directory structure.\n\n5.  Generate **custom climate indicator figures** from the output files generated by the Climpact tool.\n\n6.  Generate **custom hydrologic indicator figures** from the output files generated by the IHA tool.\n\n## How to use\n\n1.  Clone this repository and open it in a Python-capable editor (recommended: Visual Studio Code).\n\n2.  Download here the working directory.\n\n3.  Run the Preprocessing Data script.\n\n4.  Use the generated products to import them into Climpact and IHA software.\n\n5.  Run the script for automated generation of figures for climate and fluvial indicators\n\n## Indicators\n\nIn the presentation of figures in this work, a selection of climatic and hydrological indicators was made based on their ability to assess climate change and their ecological relevance.\n\n1.  Climatic indicators\n\n-   Precipitation intensity (@fig-polar-2)\n\n-   Annual precipitation (@fig-polar-3)\n\n-   Consecutive dry days (@fig-polar-4)\n\n-   Days with precipitation \\>= 30 mm (@fig-polar-5)\n\n-   Standardised Precipitation Evapostranspiration Index (@fig-polar-6)\n\n-   Annual mean daily minimum temperature (@fig-polar-7)\n\n-   Annual mean daily maximum temperature (@fig-polar-8)\n\n-   Annual warmest daily maximum temperature (@fig-polar-9)\n\n-   Days when minimum temperature \\< 0ºC (@fig-polar-10)\n\n2.  Statistical analysis of flow rates\n\n-   Flow hydrograph (@fig-polar-11)\n\n-   Boxplot of median monthly flow (@fig-polar-12)\n\n-   Percentiles of monthly flow (@fig-polar-13)\n\n-   Flow Duration Curve (@fig-polar-14)\n\n-   Median monthly flow of the entire basin (@fig-polar-15)\n\n3.  Time series of hydrological indicators\n\n-   Median flow in July (@fig-polar-16)\n\n-   High pulse duration (@fig-polar-17)\n\n-   Base flow index (@fig-polar-18)\n\n-   Small flood peak (@fig-polar-19)\n\n-   Large flood peak (@fig-polar-20)\n\n## Hydroclimatic Data Preprocessing Script\n\n### Filter CAMELS-CL data\n\n4.1.1. Dependencies and workspace\n\n4.1.1.1 Import libraries\n\n```{python}\nimport os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n```\n\n4.1.1.2. Make sure the directory exists\n\n```{python}\ndef asegurar_directorio(ruta):\n    os.makedirs(ruta, exist_ok=True)\n```\n\n4.1.1.3. Define folder paths\n\n```{python}\nos.chdir('/Users/andrearedel/Documents/Retoño')\n```\n\n```{python}\nruta_base = 'Hidroclima/Base de datos'\nruta_guardado = os.path.join(ruta_base, '0.filtrado_estaciones')\n```\n\n4.1.1.4. Create the directory if it doesn't exist\n\n```{python}\nasegurar_directorio(ruta_guardado)\n```\n\n4.1.1.5. Additional columns\n\n```{python}\ncolumnas_adicionales = ['year', 'month', 'day']\n```\n\n4.1.2. Maximum temperature filter 4.1.2.1. Read the CSV file\n\n```{python}\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmax_cr2met_C_day.csv'))\n```\n\n4.1.2.2. Filter columns based on River Basin\n\n```{python eval=false}\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9100000 <= int(col) <= 9199999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n```\n\nIn this article, we will use the Toltén River Basin, Chile, identified by the code `94`, as a case study.\n\nTo analyze a different basin:\n\n-   Change the station code range, for example, the Imperial River Basin, identified by the code `91`.\n-   Update all relevant parts of the script accordingly.\n\n```{python}\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n```\n\n4.1.2.3. Create a new Data Frame with the filtered columns\n\n```{python}\ndf_filtrado = df[columnas_filtradas]\n```\n\n4.1.2.4. Save the new Data Frame to a CSV file\n\n```{python}\n#| label: tbl-polar-1\n#| tbl-cap: \"Maximum temperature filter for the stations in each basin\"\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmax.csv'), index=False)\n\nprint(\"Filtered columns and new file of maximum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n4.1.3. Minimum Temperature filter The same process is repeated as with the maximum temperature.\n\n```{python}\n#| label: tbl-polar-2\n#| tbl-cap: \"Minimum temperature filter for the stations in each basin\"\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmin_cr2met_C_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmin.csv'), index=False)\n\nprint(\"Filtered columns and new file of minimum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n4.1.4. Precipitation filter The same process is repeated.\n\n```{python}\n#| label: tbl-polar-3\n#| tbl-cap: \"Precipitation filter for the stations in each basin\"\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/precip_cr2met_mm_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'pp.csv'), index=False)\n\nprint(\"Filtered columns and new file of precipitation for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n4.1.5. Streamflow filter The same process is repeated.\n\n```{python}\n#| label: tbl-polar-4\n#| tbl-cap: \"Streamflow filter for the stations in each basin\"\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/q_m3s_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'q.csv'), index=False)\n\nprint(\"Filtered columns and new file of streamflow for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n### Create separate CSV files for each station and variable\n\n4.2.1. Minimum Temperature 4.2.1.1. CSV file path\n\n```{python}\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmin.csv'\n```\n\n4.2.1.2. Read CSV file\n\n```{python}\ndf = pd.read_csv(archivo_csv)\n```\n\n4.2.1.3. Get the Data Frame columns\n\n```{python}\ncolumnas = df.columns\n```\n\n4.2.1.4. Create a directory to save files by column\n\n```{python}\noutput_dir = 'Hidroclima/Base de datos/1.temperaturas_min'\nos.makedirs(output_dir, exist_ok=True)\n```\n\n4.2.1.5. Iterate over the columns and save the data for `year`, `month,` and `day`\n\n```{python}\n#| label: tbl-polar-5\n#| tbl-cap: \"Daily minimum temperature for station 9437002\"\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmin'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n    \nprint(\"Files of minimum temperature (tmin) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n4.2.2. Maximum Temperature The same process is repeated\n\n```{python}\n#| label: tbl-polar-6\n#| tbl-cap: \"Daily maximum temperature for station 9437002\"\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmax.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/2.temperaturas_max'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmax'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of maximum temperature (tmax) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n4.2.3. Precipitation The same process is repeated\n\n```{python}\n#| label: tbl-polar-7\n#| tbl-cap: \"Daily precipitation for station 9437002\"\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/pp.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/3.precipitaciones'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'pp'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of precipitation (pp) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n4.2.4. Streamflow The same process is repeated\n\n```{python}\n#| label: tbl-polar-8\n#| tbl-cap: \"Daily streamflow for station 9437002\"\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/q.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/7.caudales'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'q'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of streamflow (q) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n### Split data by station\n\n4.3.1. Format data for compability with Climpact 4.3.1.1. Mapping precipitation, minimum and maximum temperature based on filename and file path\n\n```{python}\ndir_principal = 'Hidroclima/Base de datos'\n\nsubcarpetas = ['1.temperaturas_min', '2.temperaturas_max', '3.precipitaciones']\n\ncolumna_map = {\n    '1.temperaturas_min': 'tmin',\n    '2.temperaturas_max': 'tmax',\n    '3.precipitaciones': 'prcp'\n}\n\ndef obtener_archivos(subcarpeta):\n    ruta_subcarpeta = os.path.join(dir_principal, subcarpeta)\n    archivos = [archivo for archivo in os.listdir(ruta_subcarpeta) if archivo.endswith('.csv') and archivo not in ['year.csv', 'month.csv', 'day.csv']]\n    return archivos\n\ndef leer_archivo(ruta, columna):\n    df = pd.read_csv(ruta)\n    df = df.rename(columns={df.columns[-1]: columna})\n    return df\n\nestaciones_data = {}\n\nfor subcarpeta in subcarpetas:\n    columna = columna_map[subcarpeta]\n    archivos = obtener_archivos(subcarpeta)\n    \n    for archivo in archivos:\n        estacion = os.path.splitext(archivo)[0]\n        ruta_archivo = os.path.join(dir_principal, subcarpeta, archivo)\n        \n        df = leer_archivo(ruta_archivo, columna)\n        \n        if estacion not in estaciones_data:\n            estaciones_data[estacion] = df[['year', 'month', 'day', columna]]\n        else:\n            estaciones_data[estacion] = estaciones_data[estacion].merge(df[['year', 'month', 'day', columna]], on=['year', 'month', 'day'], how='outer')\n```\n\n4.3.1.2. Save files by station\n\n```{python}\noutput_dir = os.path.join(dir_principal, '4.pre_Climpact')\nos.makedirs(output_dir, exist_ok=True)\n\nfor estacion, df in estaciones_data.items():\n    for columna in ['prcp', 'tmax', 'tmin']:\n        if columna not in df.columns:\n            df[columna] = pd.NA\n    \n    df = df[['year', 'month', 'day', 'prcp', 'tmax', 'tmin']]\n```\n\n4.3.1.3. Format:\n\n-   Approximate variable values to 1 decimal place\n\n-   Convert `day`and `month` values to 2 digits\n\n-   Combine `year`, `month` and `day` into a single 'date' column\n\n-   Replace `inf`, `-inf` and `NaN` values ​​with `-99.9`\n\n-   Export as a `.txt` file\n\n-   Correct order of columns\n\n```{python}\n#| label: tbl-polar-9\n#| tbl-cap: \"List of the generated files in the output directory\"\n   \n    df[['prcp', 'tmax', 'tmin']] = df[['prcp', 'tmax', 'tmin']].apply(lambda x: round(x, 1))\n    \n    df['month'] = df['month'].apply(lambda x: f'{x:02}')\n    df['day'] = df['day'].apply(lambda x: f'{x:02}')\n    \n    df['fecha'] = df.apply(lambda row: f\"{int(row['year']):4d} {row['month']} {row['day']}\", axis=1)\n    \n    df = df.replace([float('inf'), float('-inf')], -99.9).fillna(-99.9)\n    \n    ruta_salida = os.path.join(output_dir, f'{estacion}.txt')\n    \n    with open(ruta_salida, 'w') as f:\n        for _, row in df.iterrows():\n            f.write(f\"{row['fecha']}    {row['prcp']:5.1f}     {row['tmax']:4.1f}     {row['tmin']:4.1f}\\n\")\n\nprint(\"Files for Climpact generated successfully.\")\n\narchivos_generados = sorted(os.listdir(output_dir))\ndf_archivos = pd.DataFrame(archivos_generados, columns=['Generated files'])\ndisplay(df_archivos)\n```\n\n```{python}\n#| label: tbl-polar-10\n#| tbl-cap: \"Station 9437002 file with information on each variable\"\n#| echo: false\n\nfrom IPython.display import HTML\nhtml = df_primero.head().to_html(index=False, header=False)\ndisplay(HTML(html))\n```\n\n4.3.2. Format data for compability with IHA 4.3.2.1. The same process is repeated, now for the streamflow.\n\n```{python}\ndir_entrada = os.path.join('Hidroclima', 'Base de datos', '7.caudales')\ndir_salida = os.path.join('Hidroclima', 'Base de datos', '8.pre_IHA')\n\nos.makedirs(dir_salida, exist_ok=True)\n\nfor archivo in os.listdir(dir_entrada):\n    if archivo.endswith('.csv'):\n        ruta_entrada = os.path.join(dir_entrada, archivo)\n        \n        archivo_salida = os.path.splitext(archivo)[0] + '.txt'\n        ruta_salida = os.path.join(dir_salida, archivo_salida)\n\n        df = pd.read_csv(ruta_entrada)\n\n        columnas_requeridas = {'year', 'month', 'day', 'q'}\n        if not columnas_requeridas.issubset(df.columns):\n            print(f\"The {archivo} file does not contain the required columns: {columnas_requeridas}\")\n            continue\n\n        df = df[['year', 'month', 'day', 'q']]\n```\n\n4.3.2.2. Format:\n\n-   Aproximate streamflow values to 1 decimal place\n\n-   Date column in **YYYY-MM-DD** format\n\n-   Replace `inf`, `-inf`, and `NaN` values ​​with `-1.0`\n\n-   Delete leading rows where 'q' equals -1.0\n\n-   Streamflow column named `flow`\n\n-   Export as `.txt`file\n\n```{python}\n        df = df.replace([float('inf'), float('-inf')], -1.0).fillna(-1.0)\n\n        df = df.loc[df['q'] != -1.0].reset_index(drop=True)\n\n        df['q'] = df['q'].round(1)\n\n        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n        df = df[['date', 'q']].rename(columns={'q': 'flow'})\n\n        df.to_csv(ruta_salida, index=False, header=True)\n\nprint(\"IHA files processed successfully.\")\n```\n\n### Extra files and folders for sorting results\n\n4.4.1. List of folders to create:\n\n-   Folder 5 stores the station-specific folders generated by Climpact.\n\n-   Folder 6 contains customized plots based on Climpact results.\n\n-   Folder 9 stores the Excel files generated by IHA for each station, along with their processed CSV versions.\n\n-   Folder 10 includes the figures created from IHA data.\n\n-   Folder 11 contains text files intended to be imported into QGIS for georeferencing.\n\n```{python}\nruta_base = os.path.join('Hidroclima', 'Base de datos')\n\ncarpetas = [\n    '5.Climpact',\n    '6.Figuras_Climpact',\n    '9.IHA',\n    '10.Figuras_IHA',\n    '11.Georreferenciación'\n]\n\nfor carpeta in carpetas:\n    ruta_carpeta = os.path.join(ruta_base, carpeta)\n    os.makedirs(ruta_carpeta, exist_ok=True)\n    print(f\"Folder created: {ruta_carpeta}\")\n\nprint(\"All necessary folders for the results have been created successfully.\")\n```\n\n4.4.2. Georeference the stations in the study basin\n\n```{python}\n#| label: tbl-polar-11\n#| tbl-cap: \"Information by georeferenced station\"\narchivo_entrada = \"Hidroclima/Base de datos/CAMELS_CL_v202201/catchment_attributes.csv\"\ndf = pd.read_csv(archivo_entrada)\n\ndf_filtrado = df[(df['gauge_id'] >= 9400000) & (df['gauge_id'] <= 9499999)]\n\ndf_filtrado = df_filtrado[['gauge_id', 'gauge_name', 'gauge_lat', 'gauge_lon', 'record_period_start', 'record_period_end']]\n\ndirectorio_salida = \"Hidroclima/Base de datos/11.Georreferenciación/Estaciones.csv\"\n\ndf_filtrado.to_csv(directorio_salida, index=False)\n\nprint(\"Filtered file saved as:\", directorio_salida)\n\nfrom IPython.display import display\ndisplay(df_filtrado)\n```\n\n## Generation of figures for climate indicators script\n\nBy default, Climpact generates figures for each calculated indicator at each station. However, the following script provides a general framework for creating customized figures.\n\n### General framework for customized figures\n\n5.1.1. Libraries.\n\n```{python eval=false}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom scipy.stats import linregress\n```\n\n5.1.2. Base route and output route.\n\nIn this case, the figure of the annual accumulated precipitation indicator is generated.\n\n```{python eval=false}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n```\n\n5.1.3. Selecting the indicator to be graphed.\n\nIn this case, the annual total precipitation indicator is used, identified as `prcptot` in the dataset and therefore with its corresponding station code followed by `_prcptot_ANN.csv` in its file name. To select a different indicator, simply use the name of the corresponding file that contains the desired variable, for example, `_txx_ANN.csv` and the `txx` variable for monthly maximum daily temperature.\n\n```{python eval=false}\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n```\n\n5.1.4. Create the figure.\n\nThe use of Sen's slope, the regression line, and the statistical values calculated by the Climpact software have not yet been systematically included in the figure.\n\n```{python eval=false}\n#| label: fig-polar-1\n#| fig-cap: \"Indicator of total accumulated precipitation at station 9434001\"\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Annual precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n        \n        contador += 1\n```\n\n### Suggested precipitation indicators and their figures\n\n5.2.1. Precipitation intensity (sdii).\n\nAnnual total precipitation divided by the number of wet days (when total precipitation \\>= 1.0 mm) is now graphed for each station.\n\n```{python}\n#| label: fig-polar-2\n#| fig-cap: \"Indicator of precipitation intensity at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_sdii_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'sdii']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['sdii'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['sdii'], marker='D', linestyle='-', color='black', label='Precipitation intensity')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['sdii'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation intensity\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_sdii_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.2. Anual accumulated precipitation (prcptot).\n\nAnnual sum of daily precipitation \\>= 1.0 mm is now graphed for each station. This was already calculated above.\n\n```{python}\n#| label: fig-polar-3\n#| fig-cap: \"Indicator of total accumulated precipitation at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Total Precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Anual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.3. Consecutive dry days (cdd).\n\nMaximum annual number of consecutive dry days (when precipitation \\< 1.0 mm).\n\n```{python}\n#| label: fig-polar-4\n#| fig-cap: \"Indicator of consecutive dry days at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_cdd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'cdd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['cdd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['cdd'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['cdd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Consecutive dry days\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_cdd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.4. Days with precipitation greater than 30mm (r30mm).\n\nNumber of days when precipitation \\>= 30mm.\n\n```{python}\n#| label: fig-polar-5\n#| fig-cap: \"Indicator of days with precipitation greater than 30 mm at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_r30mm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'r30mm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['r30mm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['r30mm'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['r30mm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation >= 30mm\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_r30mm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.5. Standardised Precipitation Evapotranspiration Index (SPEI)\n\nThis indicator estimates water balance using precipitation and temperature information. It provides a drought indicator. In this case, it is graphed on a 24-month scale. Due to the monthly scale of the indicator, the code has slight adjustments.\n\n```{python}\n#| label: fig-polar-6\n#| fig-cap: \"Indicator of Standardised Precipitation Evapotrasnpiration Index at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_24month_spei_MON.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'spei']]\n\n        df['time'] = pd.to_datetime(df['time'], format='%Y-%m')\n\n        df = df[df['spei'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n\n        df_pos = df[df['spei'] >= 0]\n        df_neg = df[df['spei'] < 0]\n\n        plt.plot(df.index, df['spei'], linestyle='-', color='black', label='SPEI')\n\n        plt.plot(df_pos.index, df_pos['spei'], marker='o', linestyle='None', color='black', label='SPEI ≥ 0')\n\n        plt.plot(df_neg.index, df_neg['spei'], marker='o', linestyle='None', color='gray', label='SPEI < 0')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['spei'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - SPEI compared to the last 24 months\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('SPEI', fontsize=24, fontname='Times New Roman')\n\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_spei24_MON_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n### Suggested temperature indicators and their figures\n\n5.3.1. Annual mean daily minimum temperature (tnm).\n\n```{python}\n#| label: fig-polar-7\n#| fig-cap: \"Indicator of annual mean daily minimum temperature at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_tnm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'tnm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['tnm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['tnm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['tnm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily minimum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_tnm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.3.2. Annual mean daily maximum temperature (txm).\n\n```{python}\n#| label: fig-polar-8\n#| fig-cap: \"Indicator of annual mean daily maximum temperature at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.3.3. Annual warmest daily maximum temperature (txx).\n\n```{python}\n#| label: fig-polar-9\n#| fig-cap: \"Indicator of annual warmest daily maximum temperature at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txx_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txx']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txx'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txx'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txx'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual warmest daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txx_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.3.4. Annual number of days when minimum temperature \\< 0ºC (id).\n\n```{python}\n#| label: fig-polar-10\n#| fig-cap: \"Indicator of annual numbery of days when minimum temperature is lower than 0ºC at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_fd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'fd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['fd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['fd'], marker='D', linestyle='-', color='black', label='Days T<0ºC')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['fd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Days when minimum temperature < 0ºC\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_fd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n## Generation of figures for hydrologic indicators script\n\n### Libraries and workspace.\n\n```{python}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport matplotlib.pyplot as plt\n\ninput_directory = 'Hidroclima/Base de datos/9.IHA'\n\nsheets_to_convert = ['ann', 'sco', 'lsq', 'pct', 'daily efcs', 'fdc']\n\nfor filename in os.listdir(input_directory):\n    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n        filepath = os.path.join(input_directory, filename)\n        excel_file = pd.ExcelFile(filepath)\n        \n        station_code = os.path.splitext(filename)[0]\n        \n        station_output_directory = os.path.join(input_directory, 'csv', station_code)\n        \n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for sheet in sheets_to_convert:\n            if sheet in excel_file.sheet_names:\n                df = pd.read_excel(filepath, sheet_name=sheet)\n                \n                output_filename = f\"{sheet}_{station_code}.csv\"\n                output_filepath = os.path.join(station_output_directory, output_filename)\n                \n                df.to_csv(output_filepath, index=False)\n                \nprint(\"ann, sco, fdc, pct, lsq and daily efcs files saved in its folder.\")\n```\n\n### Streamflow figures\n\n6.2.1. Simple monthly median flow for each station\n\nThe order of the months in the `sco_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n```{python}\n#| label: fig-polar-11\n#| fig-cap: \"Indicator of simple monthly median flow at station 9423001\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\n\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\nmeses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n\n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            plt.figure(figsize=(12, 8))\n            plt.plot(df_mes.index, df_mes['Median'], marker='.', linestyle='-', color='black', label='Median')\n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Median monthly flow - {station_code} Station', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.grid(True, linestyle='-', linewidth=0.5, color='lightgray')\n            plt.legend(fontsize=14)\n            plt.grid(False)\n\n            output_file = os.path.join(output_dir, f'Median_monthly_flow_{station_code}.png')\n            plt.tight_layout()\n            plt.savefig(output_file, dpi=300)\n            \n            plt.savefig(ruta_salida)\n\n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n\n            contador += 1\n            print(f'Figure saved: {output_file}')\n```\n\n6.2.2. Boxplot flow for each month calculated from all recorded years for each station\n\nThe language of the months or even the way they are written in the `ann_` file may vary. If so, adjust the `columns` variable and `id_vars` accordingly.\n\n```{python}\n#| label: fig-polar-12\n#| fig-cap: \"Boxplot of flow at station 9423001\"\nbase_directory = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = os.path.join('Hidroclima/Base de datos/10.Figuras_IHA', 'Caudal')\nif not os.path.exists(output_root_directory):\n    os.makedirs(output_root_directory)\n\ncontador = 0\n\nfor station_folder in os.listdir(base_directory):\n    station_path = os.path.join(base_directory, station_folder)\n    if os.path.isdir(station_path):\n        station_output_directory = os.path.join(output_root_directory, station_folder)\n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for filename in os.listdir(station_path):\n            if filename.startswith('ann_') and filename.endswith('.csv'):\n                input_file = os.path.join(station_path, filename)\n                \n                df = pd.read_csv(input_file, skiprows=4)\n                \n                columns = ['Year', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n                df = df[columns]\n\n                df_melted = df.melt(id_vars=['Year'], var_name='Month', value_name='Value')\n                \n                month_translation = {\n                    'January': 'January', 'February': 'February', 'March': 'March', 'April': 'April', \n                    'May': 'May', 'June': 'June', 'July': 'July', 'August': 'August', \n                    'September': 'September', 'October': 'October', 'November': 'November', \n                    'December': 'December'\n                }\n\n                df_melted['Month'] = df_melted['Month'].map(month_translation)\n                \n                plt.rcParams[\"font.family\"] = \"Times New Roman\"\n                plt.rcParams[\"font.size\"] = 12\n                plt.rcParams[\"axes.titlesize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"axes.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"xtick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"ytick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                \n                plt.figure(figsize=(12, 6))\n                sns.boxplot(\n                    x='Month', y='Value', data=df_melted,\n                    order=['January', 'February', 'March', 'April', 'May', 'June', 'July', \n                           'August', 'September', 'October', 'November', 'December'],\n                    color='gray'\n                )\n                #plt.title(f'Distribution of the median monthly flow - {station_folder} Station')\n                plt.xlabel('Month')\n                plt.ylabel('Flow (m3/s)')\n                plt.xticks(rotation=45)\n                plt.tight_layout()\n                \n                output_plot_path = os.path.join(station_output_directory, f'BOXPLOT_{filename[:-4]}.png')\n                plt.savefig(output_plot_path, dpi=300)\n                \n                if contador == 0:\n                    plt.show()\n                else:\n                    plt.close()\n\n                contador += 1\n                \n                print(f'Boxplot saved: {output_plot_path}')\n```\n\n6.2.3. Figure with the percentiles of monthly flows for all years evaluated by station.\n\nThe order of the months in the `pct_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n```{python}\n#| label: fig-polar-13\n#| fig-cap: \"Percentiles of monthly flows at station 9423001\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"pct_\") and file.endswith(\".csv\"):\n            pct_file = os.path.join(root, file)\n            \n            station_code = os.path.basename(root)\n            \n            station_output_directory = os.path.join(output_root_directory, station_code)\n            \n            if not os.path.exists(station_output_directory):\n                print(f\"Error: The output directory for station {station_code} does not exist.\")\n                continue\n            \n            df = pd.read_csv(pct_file, skiprows=8, header=None) \n            df_mes = df.iloc[:12, :6]\n            df_mes.columns = ['Month', '10%', '25%', '50%', '75%', '90%']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            \n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            plt.figure(figsize=(12, 8))\n            linestyles = ['-', '--', '-.', ':', (0, (1, 10))]\n            marcadores = ['o', 's', '^', 'D', '*']\n            \n            for percentil, linestyle, marcador in zip(['10%', '25%', '50%', '75%', '90%'], linestyles, marcadores):\n                plt.plot(df_mes.index, df_mes[percentil], marker=marcador, linestyle=linestyle, label=percentil, color='black')\n            \n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Percentiles of monthly flows for {station_code}', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14)\n            plt.grid(False)\n            plt.tight_layout()\n            \n            output_plot_path = os.path.join(station_output_directory, f'percentiles_{station_code}.png')\n            plt.savefig(output_plot_path, dpi=300)\n            \n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n            \n            contador += 1\n            \n            print(f'Figure saved: {output_plot_path}')\n```\n\n6.2.4. Graphs for each station with the probability of exceedance for each month and at an annual level.\n\nThe language of the months or even the way they are written in the `fdc_` file may vary. If so, adjust the `meses` variable accordingly.\n\n```{python}\n#| label: fig-polar-14\n#| fig-cap: \"Flow Duration Curve for January at station 9423001\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nmeses = {\n    'Annual': 'Annual', 'January': 'January', 'February': 'February', 'March': 'March',\n    'April': 'April', 'May': 'May', 'June': 'June', 'July': 'July', \n    'August': 'August', 'September': 'September', 'October': 'October', \n    'November': 'November', 'December': 'December'\n}\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"fdc_\") and file.endswith(\".csv\"):\n            fdc_file = os.path.join(root, file)\n            \n            df_headers = pd.read_csv(fdc_file, skiprows=9, nrows=1, header=None)\n            df_data = pd.read_csv(fdc_file, skiprows=11, header=None)\n            \n            col_indices = {}\n            for col_idx, col_name in enumerate(df_headers.iloc[0]):\n                if isinstance(col_name, str) and col_name.strip() in meses:\n                    col_indices[meses[col_name.strip()]] = col_idx\n            \n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            for mes, mes_label in meses.items():\n                if mes_label in col_indices:\n                    x_col = col_indices[mes_label] + 1\n                    y_col = col_indices[mes_label] \n\n                    data = df_data.iloc[:, [y_col, x_col]].dropna()\n                    data.columns = ['Caudal', 'Probabilidad']\n                    data['Probabilidad'] = data['Probabilidad']\n                    \n                    plt.figure(figsize=(12, 8))\n                    plt.plot(data['Probabilidad'], data['Caudal'], marker='o', linestyle='-', color='black')\n                    #plt.title(f'Flow Duration Curve - {mes_label} ({station_code})', fontsize=16, fontname='Times New Roman')\n                    plt.xlabel('Probability of Exceedance (%)', fontsize=14, fontname='Times New Roman')\n                    plt.ylabel('Flow (m³/s)', fontsize=14, fontname='Times New Roman')\n                    plt.grid(False)\n                    plt.tight_layout()\n                    \n                    output_file = os.path.join(output_dir, f'FDC_{mes_label}_{station_code}.png')\n                    plt.savefig(output_file, dpi=300)\n                    \n                    if contador == 1:\n                        plt.show()\n                    else:\n                        plt.close()\n                        \n                    contador += 1\n                    \nprint('Flow Duration Curve generated for each month of each station')\n```\n\n6.2.5. Figure of the streamflow of all stations present in the basin\n\nThe order of the months in the `sco_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n```{python}\n#| label: fig-polar-15\n#| fig-cap: \"Median monthly flow by station\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\nsave_path = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\nos.makedirs(save_path, exist_ok=True)\n\nlinestyles = ['-', '--', '-.', ':', (0, (1, 10)), (0, (5, 10)), (0, (3, 5)), (0, (3, 1)), (0, (5, 3)), (0, (1, 1)), (0, (5, 1)), (0, (1, 5))]\ncolores = ['black', 'darkgray', 'gray', 'lightgray', 'black', 'dimgray', 'gray', 'dimgray', 'darkgray', 'black', 'dimgray', 'black']\nplt.figure(figsize=(12, 8))\nline_counter = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            nombre_archivo = os.path.basename(sco_file)\n            codigo_estacion = nombre_archivo.split('_')[1].split('.')[0]\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            linestyle = linestyles[line_counter % len(linestyles)]\n            color = colores[line_counter % len(colores)]\n            plt.plot(df_mes.index, df_mes['Median'], linestyle=linestyle, color=color, label=f'Station {codigo_estacion}')\n            line_counter += 1\n\nplt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n#plt.title('Median monthly flow by station', fontsize=24, fontname='Times New Roman')\nplt.xlabel('Month', fontsize=24, fontname='Times New Roman')\nplt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\nplt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\nplt.yticks(fontsize=24, fontname='Times New Roman')\nplt.grid(True, linestyle='-', linewidth=0.5, color='black')\nplt.legend(fontsize=14)\nplt.grid(False)\n\nsave_file = os.path.join(save_path, 'qmonthly_TOTstations.png')\nplt.tight_layout()\nplt.savefig(save_file, dpi=300)\nplt.show()\n```\n\n### Time series figures\n\nThe language of the months, indicator and column of \"year\" or even the way they are written in the `ann_` and `sco_` file may vary.\n\nIf so, adjust:\n\n-   `indicator_names` variable\n\n-   the names for the regression in row `lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]`\n\n-   the `skiprows` variable in `sco_data` with the number of the row where the list of the respective indicator begins\n\n-   the `slope`, `intercept` and `r_squared` variables\n\n6.3.1. Median flow in July over time.\n\nIn this case, the time series of the median flow in July was selected, as it corresponds to the month with the highest flow in the study basin.\n\n6.3.1.1. Reading input files and extracting specific data related to the selected month.\n\n```{python}\nbase_folder_path = 'Hidroclima/Base de datos/9.IHA/csv/'\noutput_folder_path = 'Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/'\nos.makedirs(output_folder_path, exist_ok=True)\n\nindicator_names = {\n    'lsq_row': 'July',              \n    'ann_column': 'July',           \n    'sco_row': 'July',              \n    'plot_label': 'July'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=17, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n\n6.3.1.2. Saving the extracted data in a single `.csv` file.\n\n```{python}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n\n6.3.1.3. Graph format.\n\n```{python}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV file and figure for station {station_code} has been saved in {graph_filename}\")\n```\n\n6.3.1.4. Graph generation.\n\n```{python}\n#| label: fig-polar-16\n#| fig-cap: \"Median flow in July over time at station 9423001\"\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.2. High flow pulses duration by station\n\n6.3.2.1. Reading input files and extracting specific data related to the selected indicator.\n\n```{python}\nindicator_names = {\n    'lsq_row': 'High pulse duration',              \n    'ann_column': 'Hi pulse L',           \n    'sco_row': 'High pulse duration',              \n    'plot_label': 'High pulse duration'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=48, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n\n6.3.2.2. Saving the extracted data in a single `.csv` file.\n\n```{python}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n\n6.3.2.3. Graph format.\n\n```{python}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n```\n\n6.3.2.4. Graph generation.\n\n```{python}\n#| label: fig-polar-17\n#| fig-cap: \"High flow pulses duration over time at station 9423001\"\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.3. Base Flow Index by station\n\n6.3.3.1. Reading input files and extracting specific data related to the selected indicator.\n\n```{python}\nindicator_names = {\n    'lsq_row': 'Base flow index',              \n    'ann_column': 'Base flow',           \n    'sco_row': 'Base flow index',              \n    'plot_label': 'Base flow index'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=30, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n\n6.3.3.2. Saving the extracted data in a single `.csv` file.\n\n```{python}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n\n6.3.3.3. Graph format.\n\n```{python}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('BFI', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n```\n\n6.3.3.4. Graph generation.\n\n```{python}\n#| label: fig-polar-18\n#| fig-cap: \"Base Flow Index over time at station 9423001\"\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.4. Small Floods Peaks over time\n\nThe same process is repeated, adjusted to the specific indicator.\n\n```{python}\n#| label: fig-polar-19\n#| fig-cap: \"Small Floods Peaks over time at station 9423001\"\nindicator_names = {\n    'lsq_row': 'Small Flood peak',              \n    'ann_column': 'Sfld1 peak',           \n    'sco_row': 'Small Flood peak',              \n    'plot_label': 'Small Flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=80, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.4. Large Floods Peaks over time\n\nThe same process is repeated, adjusted to the specific indicator.\n\n```{python}\n#| label: fig-polar-20\n#| fig-cap: \"Large Floods Peaks over time at station 9423001\"\nindicator_names = {\n    'lsq_row': 'Large flood peak',              \n    'ann_column': 'Lfld1 peak',           \n    'sco_row': 'Large flood peak',              \n    'plot_label': 'Large flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=85, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 2:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```","srcMarkdownNoYaml":"\n\nThe following workflow was developed as part of an academic residency for the undergraduate Forestry Engineering program under the supervision of Dr. Isabel Rojas.\n\nThis repository contains Python scripts designed to filter, organize, and prepare daily hydrometeorological data from the *CAMELS-CL* dataset for further analysis, such as with *Climpact* and *Indicators of Hydrologic Alteration (IHA)* tools. Climpact generates **33 climate indicators** to assess climate change at each meteorological station. IHA (Indicators of Hydrologic Alteration) provides **33 indicators of hydrologic alteration** and **34 indicators related to components of ecological flow**, for each streamflow (hydrometric) station. This script allows for the **systematic preparation of results** from each station within a watershed into selected graphical figures.\n\nSome variable names and code comments are in Spanish as the original dataset and workflow were developed using Chilean climatic and hydrological data. However, all documentation, figures, and explanations are provided in English for international use. The code can be easily adapted to other languages or datasets. Variable names in Spanish follow the structure of the national dataset (Chile), but can be replaced as needed.\n\n## Overview\n\nThe scripts perform the following main tasks:\n\n1.  **Filter CAMELS-CL data** (`tmax`, `tmin`, `precip`, and `q`) for specific stations based on station codes\n\n2.  **Create CSV files** with `year`, `month`, and `day` columns plus values for each station.\n\n3.  **Split data by station**, saving individual files per station for each variable.\n\n4.  **Format data** for compatibility with Climpact and IHA:\n\n-   Remove `NA` and `inf`/`-inf` values.\n\n-   Remove column headers.\n\n-   Format output into required directory structure.\n\n5.  Generate **custom climate indicator figures** from the output files generated by the Climpact tool.\n\n6.  Generate **custom hydrologic indicator figures** from the output files generated by the IHA tool.\n\n## How to use\n\n1.  Clone this repository and open it in a Python-capable editor (recommended: Visual Studio Code).\n\n2.  Download here the working directory.\n\n3.  Run the Preprocessing Data script.\n\n4.  Use the generated products to import them into Climpact and IHA software.\n\n5.  Run the script for automated generation of figures for climate and fluvial indicators\n\n## Indicators\n\nIn the presentation of figures in this work, a selection of climatic and hydrological indicators was made based on their ability to assess climate change and their ecological relevance.\n\n1.  Climatic indicators\n\n-   Precipitation intensity (@fig-polar-2)\n\n-   Annual precipitation (@fig-polar-3)\n\n-   Consecutive dry days (@fig-polar-4)\n\n-   Days with precipitation \\>= 30 mm (@fig-polar-5)\n\n-   Standardised Precipitation Evapostranspiration Index (@fig-polar-6)\n\n-   Annual mean daily minimum temperature (@fig-polar-7)\n\n-   Annual mean daily maximum temperature (@fig-polar-8)\n\n-   Annual warmest daily maximum temperature (@fig-polar-9)\n\n-   Days when minimum temperature \\< 0ºC (@fig-polar-10)\n\n2.  Statistical analysis of flow rates\n\n-   Flow hydrograph (@fig-polar-11)\n\n-   Boxplot of median monthly flow (@fig-polar-12)\n\n-   Percentiles of monthly flow (@fig-polar-13)\n\n-   Flow Duration Curve (@fig-polar-14)\n\n-   Median monthly flow of the entire basin (@fig-polar-15)\n\n3.  Time series of hydrological indicators\n\n-   Median flow in July (@fig-polar-16)\n\n-   High pulse duration (@fig-polar-17)\n\n-   Base flow index (@fig-polar-18)\n\n-   Small flood peak (@fig-polar-19)\n\n-   Large flood peak (@fig-polar-20)\n\n## Hydroclimatic Data Preprocessing Script\n\n### Filter CAMELS-CL data\n\n4.1.1. Dependencies and workspace\n\n4.1.1.1 Import libraries\n\n```{python}\nimport os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n```\n\n4.1.1.2. Make sure the directory exists\n\n```{python}\ndef asegurar_directorio(ruta):\n    os.makedirs(ruta, exist_ok=True)\n```\n\n4.1.1.3. Define folder paths\n\n```{python}\nos.chdir('/Users/andrearedel/Documents/Retoño')\n```\n\n```{python}\nruta_base = 'Hidroclima/Base de datos'\nruta_guardado = os.path.join(ruta_base, '0.filtrado_estaciones')\n```\n\n4.1.1.4. Create the directory if it doesn't exist\n\n```{python}\nasegurar_directorio(ruta_guardado)\n```\n\n4.1.1.5. Additional columns\n\n```{python}\ncolumnas_adicionales = ['year', 'month', 'day']\n```\n\n4.1.2. Maximum temperature filter 4.1.2.1. Read the CSV file\n\n```{python}\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmax_cr2met_C_day.csv'))\n```\n\n4.1.2.2. Filter columns based on River Basin\n\n```{python eval=false}\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9100000 <= int(col) <= 9199999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n```\n\nIn this article, we will use the Toltén River Basin, Chile, identified by the code `94`, as a case study.\n\nTo analyze a different basin:\n\n-   Change the station code range, for example, the Imperial River Basin, identified by the code `91`.\n-   Update all relevant parts of the script accordingly.\n\n```{python}\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n```\n\n4.1.2.3. Create a new Data Frame with the filtered columns\n\n```{python}\ndf_filtrado = df[columnas_filtradas]\n```\n\n4.1.2.4. Save the new Data Frame to a CSV file\n\n```{python}\n#| label: tbl-polar-1\n#| tbl-cap: \"Maximum temperature filter for the stations in each basin\"\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmax.csv'), index=False)\n\nprint(\"Filtered columns and new file of maximum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n4.1.3. Minimum Temperature filter The same process is repeated as with the maximum temperature.\n\n```{python}\n#| label: tbl-polar-2\n#| tbl-cap: \"Minimum temperature filter for the stations in each basin\"\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmin_cr2met_C_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmin.csv'), index=False)\n\nprint(\"Filtered columns and new file of minimum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n4.1.4. Precipitation filter The same process is repeated.\n\n```{python}\n#| label: tbl-polar-3\n#| tbl-cap: \"Precipitation filter for the stations in each basin\"\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/precip_cr2met_mm_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'pp.csv'), index=False)\n\nprint(\"Filtered columns and new file of precipitation for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n4.1.5. Streamflow filter The same process is repeated.\n\n```{python}\n#| label: tbl-polar-4\n#| tbl-cap: \"Streamflow filter for the stations in each basin\"\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/q_m3s_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'q.csv'), index=False)\n\nprint(\"Filtered columns and new file of streamflow for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n### Create separate CSV files for each station and variable\n\n4.2.1. Minimum Temperature 4.2.1.1. CSV file path\n\n```{python}\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmin.csv'\n```\n\n4.2.1.2. Read CSV file\n\n```{python}\ndf = pd.read_csv(archivo_csv)\n```\n\n4.2.1.3. Get the Data Frame columns\n\n```{python}\ncolumnas = df.columns\n```\n\n4.2.1.4. Create a directory to save files by column\n\n```{python}\noutput_dir = 'Hidroclima/Base de datos/1.temperaturas_min'\nos.makedirs(output_dir, exist_ok=True)\n```\n\n4.2.1.5. Iterate over the columns and save the data for `year`, `month,` and `day`\n\n```{python}\n#| label: tbl-polar-5\n#| tbl-cap: \"Daily minimum temperature for station 9437002\"\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmin'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n    \nprint(\"Files of minimum temperature (tmin) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n4.2.2. Maximum Temperature The same process is repeated\n\n```{python}\n#| label: tbl-polar-6\n#| tbl-cap: \"Daily maximum temperature for station 9437002\"\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmax.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/2.temperaturas_max'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmax'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of maximum temperature (tmax) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n4.2.3. Precipitation The same process is repeated\n\n```{python}\n#| label: tbl-polar-7\n#| tbl-cap: \"Daily precipitation for station 9437002\"\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/pp.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/3.precipitaciones'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'pp'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of precipitation (pp) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n4.2.4. Streamflow The same process is repeated\n\n```{python}\n#| label: tbl-polar-8\n#| tbl-cap: \"Daily streamflow for station 9437002\"\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/q.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/7.caudales'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'q'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of streamflow (q) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n### Split data by station\n\n4.3.1. Format data for compability with Climpact 4.3.1.1. Mapping precipitation, minimum and maximum temperature based on filename and file path\n\n```{python}\ndir_principal = 'Hidroclima/Base de datos'\n\nsubcarpetas = ['1.temperaturas_min', '2.temperaturas_max', '3.precipitaciones']\n\ncolumna_map = {\n    '1.temperaturas_min': 'tmin',\n    '2.temperaturas_max': 'tmax',\n    '3.precipitaciones': 'prcp'\n}\n\ndef obtener_archivos(subcarpeta):\n    ruta_subcarpeta = os.path.join(dir_principal, subcarpeta)\n    archivos = [archivo for archivo in os.listdir(ruta_subcarpeta) if archivo.endswith('.csv') and archivo not in ['year.csv', 'month.csv', 'day.csv']]\n    return archivos\n\ndef leer_archivo(ruta, columna):\n    df = pd.read_csv(ruta)\n    df = df.rename(columns={df.columns[-1]: columna})\n    return df\n\nestaciones_data = {}\n\nfor subcarpeta in subcarpetas:\n    columna = columna_map[subcarpeta]\n    archivos = obtener_archivos(subcarpeta)\n    \n    for archivo in archivos:\n        estacion = os.path.splitext(archivo)[0]\n        ruta_archivo = os.path.join(dir_principal, subcarpeta, archivo)\n        \n        df = leer_archivo(ruta_archivo, columna)\n        \n        if estacion not in estaciones_data:\n            estaciones_data[estacion] = df[['year', 'month', 'day', columna]]\n        else:\n            estaciones_data[estacion] = estaciones_data[estacion].merge(df[['year', 'month', 'day', columna]], on=['year', 'month', 'day'], how='outer')\n```\n\n4.3.1.2. Save files by station\n\n```{python}\noutput_dir = os.path.join(dir_principal, '4.pre_Climpact')\nos.makedirs(output_dir, exist_ok=True)\n\nfor estacion, df in estaciones_data.items():\n    for columna in ['prcp', 'tmax', 'tmin']:\n        if columna not in df.columns:\n            df[columna] = pd.NA\n    \n    df = df[['year', 'month', 'day', 'prcp', 'tmax', 'tmin']]\n```\n\n4.3.1.3. Format:\n\n-   Approximate variable values to 1 decimal place\n\n-   Convert `day`and `month` values to 2 digits\n\n-   Combine `year`, `month` and `day` into a single 'date' column\n\n-   Replace `inf`, `-inf` and `NaN` values ​​with `-99.9`\n\n-   Export as a `.txt` file\n\n-   Correct order of columns\n\n```{python}\n#| label: tbl-polar-9\n#| tbl-cap: \"List of the generated files in the output directory\"\n   \n    df[['prcp', 'tmax', 'tmin']] = df[['prcp', 'tmax', 'tmin']].apply(lambda x: round(x, 1))\n    \n    df['month'] = df['month'].apply(lambda x: f'{x:02}')\n    df['day'] = df['day'].apply(lambda x: f'{x:02}')\n    \n    df['fecha'] = df.apply(lambda row: f\"{int(row['year']):4d} {row['month']} {row['day']}\", axis=1)\n    \n    df = df.replace([float('inf'), float('-inf')], -99.9).fillna(-99.9)\n    \n    ruta_salida = os.path.join(output_dir, f'{estacion}.txt')\n    \n    with open(ruta_salida, 'w') as f:\n        for _, row in df.iterrows():\n            f.write(f\"{row['fecha']}    {row['prcp']:5.1f}     {row['tmax']:4.1f}     {row['tmin']:4.1f}\\n\")\n\nprint(\"Files for Climpact generated successfully.\")\n\narchivos_generados = sorted(os.listdir(output_dir))\ndf_archivos = pd.DataFrame(archivos_generados, columns=['Generated files'])\ndisplay(df_archivos)\n```\n\n```{python}\n#| label: tbl-polar-10\n#| tbl-cap: \"Station 9437002 file with information on each variable\"\n#| echo: false\n\nfrom IPython.display import HTML\nhtml = df_primero.head().to_html(index=False, header=False)\ndisplay(HTML(html))\n```\n\n4.3.2. Format data for compability with IHA 4.3.2.1. The same process is repeated, now for the streamflow.\n\n```{python}\ndir_entrada = os.path.join('Hidroclima', 'Base de datos', '7.caudales')\ndir_salida = os.path.join('Hidroclima', 'Base de datos', '8.pre_IHA')\n\nos.makedirs(dir_salida, exist_ok=True)\n\nfor archivo in os.listdir(dir_entrada):\n    if archivo.endswith('.csv'):\n        ruta_entrada = os.path.join(dir_entrada, archivo)\n        \n        archivo_salida = os.path.splitext(archivo)[0] + '.txt'\n        ruta_salida = os.path.join(dir_salida, archivo_salida)\n\n        df = pd.read_csv(ruta_entrada)\n\n        columnas_requeridas = {'year', 'month', 'day', 'q'}\n        if not columnas_requeridas.issubset(df.columns):\n            print(f\"The {archivo} file does not contain the required columns: {columnas_requeridas}\")\n            continue\n\n        df = df[['year', 'month', 'day', 'q']]\n```\n\n4.3.2.2. Format:\n\n-   Aproximate streamflow values to 1 decimal place\n\n-   Date column in **YYYY-MM-DD** format\n\n-   Replace `inf`, `-inf`, and `NaN` values ​​with `-1.0`\n\n-   Delete leading rows where 'q' equals -1.0\n\n-   Streamflow column named `flow`\n\n-   Export as `.txt`file\n\n```{python}\n        df = df.replace([float('inf'), float('-inf')], -1.0).fillna(-1.0)\n\n        df = df.loc[df['q'] != -1.0].reset_index(drop=True)\n\n        df['q'] = df['q'].round(1)\n\n        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n        df = df[['date', 'q']].rename(columns={'q': 'flow'})\n\n        df.to_csv(ruta_salida, index=False, header=True)\n\nprint(\"IHA files processed successfully.\")\n```\n\n### Extra files and folders for sorting results\n\n4.4.1. List of folders to create:\n\n-   Folder 5 stores the station-specific folders generated by Climpact.\n\n-   Folder 6 contains customized plots based on Climpact results.\n\n-   Folder 9 stores the Excel files generated by IHA for each station, along with their processed CSV versions.\n\n-   Folder 10 includes the figures created from IHA data.\n\n-   Folder 11 contains text files intended to be imported into QGIS for georeferencing.\n\n```{python}\nruta_base = os.path.join('Hidroclima', 'Base de datos')\n\ncarpetas = [\n    '5.Climpact',\n    '6.Figuras_Climpact',\n    '9.IHA',\n    '10.Figuras_IHA',\n    '11.Georreferenciación'\n]\n\nfor carpeta in carpetas:\n    ruta_carpeta = os.path.join(ruta_base, carpeta)\n    os.makedirs(ruta_carpeta, exist_ok=True)\n    print(f\"Folder created: {ruta_carpeta}\")\n\nprint(\"All necessary folders for the results have been created successfully.\")\n```\n\n4.4.2. Georeference the stations in the study basin\n\n```{python}\n#| label: tbl-polar-11\n#| tbl-cap: \"Information by georeferenced station\"\narchivo_entrada = \"Hidroclima/Base de datos/CAMELS_CL_v202201/catchment_attributes.csv\"\ndf = pd.read_csv(archivo_entrada)\n\ndf_filtrado = df[(df['gauge_id'] >= 9400000) & (df['gauge_id'] <= 9499999)]\n\ndf_filtrado = df_filtrado[['gauge_id', 'gauge_name', 'gauge_lat', 'gauge_lon', 'record_period_start', 'record_period_end']]\n\ndirectorio_salida = \"Hidroclima/Base de datos/11.Georreferenciación/Estaciones.csv\"\n\ndf_filtrado.to_csv(directorio_salida, index=False)\n\nprint(\"Filtered file saved as:\", directorio_salida)\n\nfrom IPython.display import display\ndisplay(df_filtrado)\n```\n\n## Generation of figures for climate indicators script\n\nBy default, Climpact generates figures for each calculated indicator at each station. However, the following script provides a general framework for creating customized figures.\n\n### General framework for customized figures\n\n5.1.1. Libraries.\n\n```{python eval=false}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom scipy.stats import linregress\n```\n\n5.1.2. Base route and output route.\n\nIn this case, the figure of the annual accumulated precipitation indicator is generated.\n\n```{python eval=false}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n```\n\n5.1.3. Selecting the indicator to be graphed.\n\nIn this case, the annual total precipitation indicator is used, identified as `prcptot` in the dataset and therefore with its corresponding station code followed by `_prcptot_ANN.csv` in its file name. To select a different indicator, simply use the name of the corresponding file that contains the desired variable, for example, `_txx_ANN.csv` and the `txx` variable for monthly maximum daily temperature.\n\n```{python eval=false}\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n```\n\n5.1.4. Create the figure.\n\nThe use of Sen's slope, the regression line, and the statistical values calculated by the Climpact software have not yet been systematically included in the figure.\n\n```{python eval=false}\n#| label: fig-polar-1\n#| fig-cap: \"Indicator of total accumulated precipitation at station 9434001\"\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Annual precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n        \n        contador += 1\n```\n\n### Suggested precipitation indicators and their figures\n\n5.2.1. Precipitation intensity (sdii).\n\nAnnual total precipitation divided by the number of wet days (when total precipitation \\>= 1.0 mm) is now graphed for each station.\n\n```{python}\n#| label: fig-polar-2\n#| fig-cap: \"Indicator of precipitation intensity at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_sdii_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'sdii']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['sdii'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['sdii'], marker='D', linestyle='-', color='black', label='Precipitation intensity')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['sdii'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation intensity\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_sdii_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.2. Anual accumulated precipitation (prcptot).\n\nAnnual sum of daily precipitation \\>= 1.0 mm is now graphed for each station. This was already calculated above.\n\n```{python}\n#| label: fig-polar-3\n#| fig-cap: \"Indicator of total accumulated precipitation at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Total Precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Anual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.3. Consecutive dry days (cdd).\n\nMaximum annual number of consecutive dry days (when precipitation \\< 1.0 mm).\n\n```{python}\n#| label: fig-polar-4\n#| fig-cap: \"Indicator of consecutive dry days at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_cdd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'cdd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['cdd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['cdd'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['cdd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Consecutive dry days\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_cdd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.4. Days with precipitation greater than 30mm (r30mm).\n\nNumber of days when precipitation \\>= 30mm.\n\n```{python}\n#| label: fig-polar-5\n#| fig-cap: \"Indicator of days with precipitation greater than 30 mm at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_r30mm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'r30mm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['r30mm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['r30mm'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['r30mm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation >= 30mm\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_r30mm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.2.5. Standardised Precipitation Evapotranspiration Index (SPEI)\n\nThis indicator estimates water balance using precipitation and temperature information. It provides a drought indicator. In this case, it is graphed on a 24-month scale. Due to the monthly scale of the indicator, the code has slight adjustments.\n\n```{python}\n#| label: fig-polar-6\n#| fig-cap: \"Indicator of Standardised Precipitation Evapotrasnpiration Index at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_24month_spei_MON.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'spei']]\n\n        df['time'] = pd.to_datetime(df['time'], format='%Y-%m')\n\n        df = df[df['spei'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n\n        df_pos = df[df['spei'] >= 0]\n        df_neg = df[df['spei'] < 0]\n\n        plt.plot(df.index, df['spei'], linestyle='-', color='black', label='SPEI')\n\n        plt.plot(df_pos.index, df_pos['spei'], marker='o', linestyle='None', color='black', label='SPEI ≥ 0')\n\n        plt.plot(df_neg.index, df_neg['spei'], marker='o', linestyle='None', color='gray', label='SPEI < 0')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['spei'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - SPEI compared to the last 24 months\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('SPEI', fontsize=24, fontname='Times New Roman')\n\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_spei24_MON_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n### Suggested temperature indicators and their figures\n\n5.3.1. Annual mean daily minimum temperature (tnm).\n\n```{python}\n#| label: fig-polar-7\n#| fig-cap: \"Indicator of annual mean daily minimum temperature at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_tnm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'tnm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['tnm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['tnm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['tnm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily minimum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_tnm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.3.2. Annual mean daily maximum temperature (txm).\n\n```{python}\n#| label: fig-polar-8\n#| fig-cap: \"Indicator of annual mean daily maximum temperature at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.3.3. Annual warmest daily maximum temperature (txx).\n\n```{python}\n#| label: fig-polar-9\n#| fig-cap: \"Indicator of annual warmest daily maximum temperature at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txx_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txx']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txx'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txx'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txx'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual warmest daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txx_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n5.3.4. Annual number of days when minimum temperature \\< 0ºC (id).\n\n```{python}\n#| label: fig-polar-10\n#| fig-cap: \"Indicator of annual numbery of days when minimum temperature is lower than 0ºC at station 9423001\"\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_fd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'fd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['fd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['fd'], marker='D', linestyle='-', color='black', label='Days T<0ºC')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['fd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Days when minimum temperature < 0ºC\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_fd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n## Generation of figures for hydrologic indicators script\n\n### Libraries and workspace.\n\n```{python}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport matplotlib.pyplot as plt\n\ninput_directory = 'Hidroclima/Base de datos/9.IHA'\n\nsheets_to_convert = ['ann', 'sco', 'lsq', 'pct', 'daily efcs', 'fdc']\n\nfor filename in os.listdir(input_directory):\n    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n        filepath = os.path.join(input_directory, filename)\n        excel_file = pd.ExcelFile(filepath)\n        \n        station_code = os.path.splitext(filename)[0]\n        \n        station_output_directory = os.path.join(input_directory, 'csv', station_code)\n        \n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for sheet in sheets_to_convert:\n            if sheet in excel_file.sheet_names:\n                df = pd.read_excel(filepath, sheet_name=sheet)\n                \n                output_filename = f\"{sheet}_{station_code}.csv\"\n                output_filepath = os.path.join(station_output_directory, output_filename)\n                \n                df.to_csv(output_filepath, index=False)\n                \nprint(\"ann, sco, fdc, pct, lsq and daily efcs files saved in its folder.\")\n```\n\n### Streamflow figures\n\n6.2.1. Simple monthly median flow for each station\n\nThe order of the months in the `sco_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n```{python}\n#| label: fig-polar-11\n#| fig-cap: \"Indicator of simple monthly median flow at station 9423001\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\n\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\nmeses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n\n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            plt.figure(figsize=(12, 8))\n            plt.plot(df_mes.index, df_mes['Median'], marker='.', linestyle='-', color='black', label='Median')\n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Median monthly flow - {station_code} Station', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.grid(True, linestyle='-', linewidth=0.5, color='lightgray')\n            plt.legend(fontsize=14)\n            plt.grid(False)\n\n            output_file = os.path.join(output_dir, f'Median_monthly_flow_{station_code}.png')\n            plt.tight_layout()\n            plt.savefig(output_file, dpi=300)\n            \n            plt.savefig(ruta_salida)\n\n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n\n            contador += 1\n            print(f'Figure saved: {output_file}')\n```\n\n6.2.2. Boxplot flow for each month calculated from all recorded years for each station\n\nThe language of the months or even the way they are written in the `ann_` file may vary. If so, adjust the `columns` variable and `id_vars` accordingly.\n\n```{python}\n#| label: fig-polar-12\n#| fig-cap: \"Boxplot of flow at station 9423001\"\nbase_directory = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = os.path.join('Hidroclima/Base de datos/10.Figuras_IHA', 'Caudal')\nif not os.path.exists(output_root_directory):\n    os.makedirs(output_root_directory)\n\ncontador = 0\n\nfor station_folder in os.listdir(base_directory):\n    station_path = os.path.join(base_directory, station_folder)\n    if os.path.isdir(station_path):\n        station_output_directory = os.path.join(output_root_directory, station_folder)\n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for filename in os.listdir(station_path):\n            if filename.startswith('ann_') and filename.endswith('.csv'):\n                input_file = os.path.join(station_path, filename)\n                \n                df = pd.read_csv(input_file, skiprows=4)\n                \n                columns = ['Year', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n                df = df[columns]\n\n                df_melted = df.melt(id_vars=['Year'], var_name='Month', value_name='Value')\n                \n                month_translation = {\n                    'January': 'January', 'February': 'February', 'March': 'March', 'April': 'April', \n                    'May': 'May', 'June': 'June', 'July': 'July', 'August': 'August', \n                    'September': 'September', 'October': 'October', 'November': 'November', \n                    'December': 'December'\n                }\n\n                df_melted['Month'] = df_melted['Month'].map(month_translation)\n                \n                plt.rcParams[\"font.family\"] = \"Times New Roman\"\n                plt.rcParams[\"font.size\"] = 12\n                plt.rcParams[\"axes.titlesize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"axes.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"xtick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"ytick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                \n                plt.figure(figsize=(12, 6))\n                sns.boxplot(\n                    x='Month', y='Value', data=df_melted,\n                    order=['January', 'February', 'March', 'April', 'May', 'June', 'July', \n                           'August', 'September', 'October', 'November', 'December'],\n                    color='gray'\n                )\n                #plt.title(f'Distribution of the median monthly flow - {station_folder} Station')\n                plt.xlabel('Month')\n                plt.ylabel('Flow (m3/s)')\n                plt.xticks(rotation=45)\n                plt.tight_layout()\n                \n                output_plot_path = os.path.join(station_output_directory, f'BOXPLOT_{filename[:-4]}.png')\n                plt.savefig(output_plot_path, dpi=300)\n                \n                if contador == 0:\n                    plt.show()\n                else:\n                    plt.close()\n\n                contador += 1\n                \n                print(f'Boxplot saved: {output_plot_path}')\n```\n\n6.2.3. Figure with the percentiles of monthly flows for all years evaluated by station.\n\nThe order of the months in the `pct_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n```{python}\n#| label: fig-polar-13\n#| fig-cap: \"Percentiles of monthly flows at station 9423001\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"pct_\") and file.endswith(\".csv\"):\n            pct_file = os.path.join(root, file)\n            \n            station_code = os.path.basename(root)\n            \n            station_output_directory = os.path.join(output_root_directory, station_code)\n            \n            if not os.path.exists(station_output_directory):\n                print(f\"Error: The output directory for station {station_code} does not exist.\")\n                continue\n            \n            df = pd.read_csv(pct_file, skiprows=8, header=None) \n            df_mes = df.iloc[:12, :6]\n            df_mes.columns = ['Month', '10%', '25%', '50%', '75%', '90%']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            \n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            plt.figure(figsize=(12, 8))\n            linestyles = ['-', '--', '-.', ':', (0, (1, 10))]\n            marcadores = ['o', 's', '^', 'D', '*']\n            \n            for percentil, linestyle, marcador in zip(['10%', '25%', '50%', '75%', '90%'], linestyles, marcadores):\n                plt.plot(df_mes.index, df_mes[percentil], marker=marcador, linestyle=linestyle, label=percentil, color='black')\n            \n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Percentiles of monthly flows for {station_code}', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14)\n            plt.grid(False)\n            plt.tight_layout()\n            \n            output_plot_path = os.path.join(station_output_directory, f'percentiles_{station_code}.png')\n            plt.savefig(output_plot_path, dpi=300)\n            \n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n            \n            contador += 1\n            \n            print(f'Figure saved: {output_plot_path}')\n```\n\n6.2.4. Graphs for each station with the probability of exceedance for each month and at an annual level.\n\nThe language of the months or even the way they are written in the `fdc_` file may vary. If so, adjust the `meses` variable accordingly.\n\n```{python}\n#| label: fig-polar-14\n#| fig-cap: \"Flow Duration Curve for January at station 9423001\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nmeses = {\n    'Annual': 'Annual', 'January': 'January', 'February': 'February', 'March': 'March',\n    'April': 'April', 'May': 'May', 'June': 'June', 'July': 'July', \n    'August': 'August', 'September': 'September', 'October': 'October', \n    'November': 'November', 'December': 'December'\n}\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"fdc_\") and file.endswith(\".csv\"):\n            fdc_file = os.path.join(root, file)\n            \n            df_headers = pd.read_csv(fdc_file, skiprows=9, nrows=1, header=None)\n            df_data = pd.read_csv(fdc_file, skiprows=11, header=None)\n            \n            col_indices = {}\n            for col_idx, col_name in enumerate(df_headers.iloc[0]):\n                if isinstance(col_name, str) and col_name.strip() in meses:\n                    col_indices[meses[col_name.strip()]] = col_idx\n            \n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            for mes, mes_label in meses.items():\n                if mes_label in col_indices:\n                    x_col = col_indices[mes_label] + 1\n                    y_col = col_indices[mes_label] \n\n                    data = df_data.iloc[:, [y_col, x_col]].dropna()\n                    data.columns = ['Caudal', 'Probabilidad']\n                    data['Probabilidad'] = data['Probabilidad']\n                    \n                    plt.figure(figsize=(12, 8))\n                    plt.plot(data['Probabilidad'], data['Caudal'], marker='o', linestyle='-', color='black')\n                    #plt.title(f'Flow Duration Curve - {mes_label} ({station_code})', fontsize=16, fontname='Times New Roman')\n                    plt.xlabel('Probability of Exceedance (%)', fontsize=14, fontname='Times New Roman')\n                    plt.ylabel('Flow (m³/s)', fontsize=14, fontname='Times New Roman')\n                    plt.grid(False)\n                    plt.tight_layout()\n                    \n                    output_file = os.path.join(output_dir, f'FDC_{mes_label}_{station_code}.png')\n                    plt.savefig(output_file, dpi=300)\n                    \n                    if contador == 1:\n                        plt.show()\n                    else:\n                        plt.close()\n                        \n                    contador += 1\n                    \nprint('Flow Duration Curve generated for each month of each station')\n```\n\n6.2.5. Figure of the streamflow of all stations present in the basin\n\nThe order of the months in the `sco_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n```{python}\n#| label: fig-polar-15\n#| fig-cap: \"Median monthly flow by station\"\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\nsave_path = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\nos.makedirs(save_path, exist_ok=True)\n\nlinestyles = ['-', '--', '-.', ':', (0, (1, 10)), (0, (5, 10)), (0, (3, 5)), (0, (3, 1)), (0, (5, 3)), (0, (1, 1)), (0, (5, 1)), (0, (1, 5))]\ncolores = ['black', 'darkgray', 'gray', 'lightgray', 'black', 'dimgray', 'gray', 'dimgray', 'darkgray', 'black', 'dimgray', 'black']\nplt.figure(figsize=(12, 8))\nline_counter = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            nombre_archivo = os.path.basename(sco_file)\n            codigo_estacion = nombre_archivo.split('_')[1].split('.')[0]\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            linestyle = linestyles[line_counter % len(linestyles)]\n            color = colores[line_counter % len(colores)]\n            plt.plot(df_mes.index, df_mes['Median'], linestyle=linestyle, color=color, label=f'Station {codigo_estacion}')\n            line_counter += 1\n\nplt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n#plt.title('Median monthly flow by station', fontsize=24, fontname='Times New Roman')\nplt.xlabel('Month', fontsize=24, fontname='Times New Roman')\nplt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\nplt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\nplt.yticks(fontsize=24, fontname='Times New Roman')\nplt.grid(True, linestyle='-', linewidth=0.5, color='black')\nplt.legend(fontsize=14)\nplt.grid(False)\n\nsave_file = os.path.join(save_path, 'qmonthly_TOTstations.png')\nplt.tight_layout()\nplt.savefig(save_file, dpi=300)\nplt.show()\n```\n\n### Time series figures\n\nThe language of the months, indicator and column of \"year\" or even the way they are written in the `ann_` and `sco_` file may vary.\n\nIf so, adjust:\n\n-   `indicator_names` variable\n\n-   the names for the regression in row `lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]`\n\n-   the `skiprows` variable in `sco_data` with the number of the row where the list of the respective indicator begins\n\n-   the `slope`, `intercept` and `r_squared` variables\n\n6.3.1. Median flow in July over time.\n\nIn this case, the time series of the median flow in July was selected, as it corresponds to the month with the highest flow in the study basin.\n\n6.3.1.1. Reading input files and extracting specific data related to the selected month.\n\n```{python}\nbase_folder_path = 'Hidroclima/Base de datos/9.IHA/csv/'\noutput_folder_path = 'Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/'\nos.makedirs(output_folder_path, exist_ok=True)\n\nindicator_names = {\n    'lsq_row': 'July',              \n    'ann_column': 'July',           \n    'sco_row': 'July',              \n    'plot_label': 'July'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=17, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n\n6.3.1.2. Saving the extracted data in a single `.csv` file.\n\n```{python}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n\n6.3.1.3. Graph format.\n\n```{python}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV file and figure for station {station_code} has been saved in {graph_filename}\")\n```\n\n6.3.1.4. Graph generation.\n\n```{python}\n#| label: fig-polar-16\n#| fig-cap: \"Median flow in July over time at station 9423001\"\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.2. High flow pulses duration by station\n\n6.3.2.1. Reading input files and extracting specific data related to the selected indicator.\n\n```{python}\nindicator_names = {\n    'lsq_row': 'High pulse duration',              \n    'ann_column': 'Hi pulse L',           \n    'sco_row': 'High pulse duration',              \n    'plot_label': 'High pulse duration'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=48, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n\n6.3.2.2. Saving the extracted data in a single `.csv` file.\n\n```{python}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n\n6.3.2.3. Graph format.\n\n```{python}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n```\n\n6.3.2.4. Graph generation.\n\n```{python}\n#| label: fig-polar-17\n#| fig-cap: \"High flow pulses duration over time at station 9423001\"\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.3. Base Flow Index by station\n\n6.3.3.1. Reading input files and extracting specific data related to the selected indicator.\n\n```{python}\nindicator_names = {\n    'lsq_row': 'Base flow index',              \n    'ann_column': 'Base flow',           \n    'sco_row': 'Base flow index',              \n    'plot_label': 'Base flow index'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=30, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n\n6.3.3.2. Saving the extracted data in a single `.csv` file.\n\n```{python}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n\n6.3.3.3. Graph format.\n\n```{python}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('BFI', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n```\n\n6.3.3.4. Graph generation.\n\n```{python}\n#| label: fig-polar-18\n#| fig-cap: \"Base Flow Index over time at station 9423001\"\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.4. Small Floods Peaks over time\n\nThe same process is repeated, adjusted to the specific indicator.\n\n```{python}\n#| label: fig-polar-19\n#| fig-cap: \"Small Floods Peaks over time at station 9423001\"\nindicator_names = {\n    'lsq_row': 'Small Flood peak',              \n    'ann_column': 'Sfld1 peak',           \n    'sco_row': 'Small Flood peak',              \n    'plot_label': 'Small Flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=80, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n6.3.4. Large Floods Peaks over time\n\nThe same process is repeated, adjusted to the specific indicator.\n\n```{python}\n#| label: fig-polar-20\n#| fig-cap: \"Large Floods Peaks over time at station 9423001\"\nindicator_names = {\n    'lsq_row': 'Large flood peak',              \n    'ann_column': 'Lfld1 peak',           \n    'sco_row': 'Large flood peak',              \n    'plot_label': 'Large flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=85, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 2:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"number-sections":true,"output-file":"indicadores.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","theme":"sandstone","title":"Automated generation of hydroclimatic indicators","author":"Andrea Redel","editor":"visual","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"indicadores.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"title":"Automated generation of hydroclimatic indicators","author":"Andrea Redel","editor":"visual","jupyter":"python3"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html"]}