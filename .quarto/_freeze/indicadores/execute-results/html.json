{
  "hash": "d96839cb71bbdfc66e78d7280829f254",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Automated generation of hydroclimatic indicators\nauthor: \"Andrea Redel\"\nformat:\n  html:\n    code-fold: true\n    toc: true\n    number-sections: true\n    theme: sandstone\n    code-tools: true\n  #pdf: default\neditor: visual\njupyter: python3\n---\n\nThe following workflow was developed as part of an academic residency for the undergraduate Forestry Engineering program under the supervision of Dr. Isabel Rojas.\n\nThis repository contains Python scripts designed to filter, organize, and prepare daily hydrometeorological data from the *CAMELS-CL* dataset for further analysis, such as with *Climpact* and *Indicators of Hydrologic Alteration (IHA)* tools. Climpact generates **33 climate indicators** to assess climate change at each meteorological station. IHA (Indicators of Hydrologic Alteration) provides **33 indicators of hydrologic alteration** and **34 indicators related to components of ecological flow**, for each streamflow (hydrometric) station. This script allows for the **systematic preparation of results** from each station within a watershed into selected graphical figures.\n\nSome variable names and code comments are in Spanish as the original dataset and workflow were developed using Chilean climatic and hydrological data. However, all documentation, figures, and explanations are provided in English for international use. The code can be easily adapted to other languages or datasets. Variable names in Spanish follow the structure of the national dataset (Chile), but can be replaced as needed.\n\n## Overview\n\nThe scripts perform the following main tasks:\n\n1.  **Filter CAMELS-CL data** (`tmax`, `tmin`, `precip`, and `q`) for specific stations based on station codes\n\n2.  **Create CSV files** with `year`, `month`, and `day` columns plus values for each station.\n\n3.  **Split data by station**, saving individual files per station for each variable.\n\n4.  **Format data** for compatibility with Climpact and IHA:\n\n-   Remove `NA` and `inf`/`-inf` values.\n\n-   Remove column headers.\n\n-   Format output into required directory structure.\n\n5.  Generate **custom climate indicator figures** from the output files generated by the Climpact tool.\n\n6.  Generate **custom hydrologic indicator figures** from the output files generated by the IHA tool.\n\n## How to use\n\n1.  Clone this repository and open it in a Python-capable editor (recommended: Visual Studio Code).\n\n2.  Download here the working directory.\n\n3.  Run the Preprocessing Data script.\n\n4.  Use the generated products to import them into Climpact and IHA software.\n\n5.  Run the script for automated generation of figures for climate and fluvial indicators\n\n## Indicators\n\nIn the presentation of figures in this work, a selection of climatic and hydrological indicators was made based on their ability to assess climate change and their ecological relevance.\n\n1.  Climatic indicators\n\n-   Precipitation intensity (@fig-polar-2)\n\n-   Annual precipitation (@fig-polar-3)\n\n-   Consecutive dry days (@fig-polar-4)\n\n-   Days with precipitation \\>= 30 mm (@fig-polar-5)\n\n-   Standardised Precipitation Evapostranspiration Index (@fig-polar-6)\n\n-   Annual mean daily minimum temperature (@fig-polar-7)\n\n-   Annual mean daily maximum temperature (@fig-polar-8)\n\n-   Annual warmest daily maximum temperature (@fig-polar-9)\n\n-   Days when minimum temperature \\< 0ºC (@fig-polar-10)\n\n2.  Statistical analysis of flow rates\n\n-   Flow hydrograph (@fig-polar-11)\n\n-   Boxplot of median monthly flow (@fig-polar-12)\n\n-   Percentiles of monthly flow (@fig-polar-13)\n\n-   Flow Duration Curve (@fig-polar-14)\n\n-   Median monthly flow of the entire basin (@fig-polar-15)\n\n3.  Time series of hydrological indicators\n\n-   Median flow in July (@fig-polar-16)\n\n-   High pulse duration (@fig-polar-17)\n\n-   Base flow index (@fig-polar-18)\n\n-   Small flood peak (@fig-polar-19)\n\n-   Large flood peak (@fig-polar-20)\n\n## Hydroclimatic Data Preprocessing Script\n\n### Filter CAMELS-CL data\n\n4.1.1. Dependencies and workspace\n\n4.1.1.1 Import libraries\n\n::: {#ba33fe16 .cell execution_count=1}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n```\n:::\n\n\n4.1.1.2. Make sure the directory exists\n\n::: {#ebe0aad8 .cell execution_count=2}\n``` {.python .cell-code}\ndef asegurar_directorio(ruta):\n    os.makedirs(ruta, exist_ok=True)\n```\n:::\n\n\n4.1.1.3. Define folder paths\n\n::: {#6da0c372 .cell execution_count=3}\n``` {.python .cell-code}\nos.chdir('/Users/andrearedel/Documents/Retoño')\n```\n:::\n\n\n::: {#fa7497ed .cell execution_count=4}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos'\nruta_guardado = os.path.join(ruta_base, '0.filtrado_estaciones')\n```\n:::\n\n\n4.1.1.4. Create the directory if it doesn't exist\n\n::: {#6881e123 .cell execution_count=5}\n``` {.python .cell-code}\nasegurar_directorio(ruta_guardado)\n```\n:::\n\n\n4.1.1.5. Additional columns\n\n::: {#224a73d7 .cell execution_count=6}\n``` {.python .cell-code}\ncolumnas_adicionales = ['year', 'month', 'day']\n```\n:::\n\n\n4.1.2. Maximum temperature filter 4.1.2.1. Read the CSV file\n\n::: {#80d050a9 .cell execution_count=7}\n``` {.python .cell-code}\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmax_cr2met_C_day.csv'))\n```\n:::\n\n\n4.1.2.2. Filter columns based on River Basin\n\n::: {#3dba27e6 .cell execution_count=8}\n``` {.python .cell-code}\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9100000 <= int(col) <= 9199999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n```\n:::\n\n\nIn this article, we will use the Toltén River Basin, Chile, identified by the code `94`, as a case study.\n\nTo analyze a different basin:\n\n-   Change the station code range, for example, the Imperial River Basin, identified by the code `91`.\n-   Update all relevant parts of the script accordingly.\n\n::: {#1e2536f1 .cell execution_count=9}\n``` {.python .cell-code}\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n```\n:::\n\n\n4.1.2.3. Create a new Data Frame with the filtered columns\n\n::: {#a8cc9e1f .cell execution_count=10}\n``` {.python .cell-code}\ndf_filtrado = df[columnas_filtradas]\n```\n:::\n\n\n4.1.2.4. Save the new Data Frame to a CSV file\n\n::: {#tbl-polar-1 .cell tbl-cap='Maximum temperature filter for the stations in each basin' execution_count=11}\n``` {.python .cell-code}\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmax.csv'), index=False)\n\nprint(\"Filtered columns and new file of maximum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiltered columns and new file of maximum temperatures for the basin's stations saved.\nPreview:\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>1001001</th>\n      <th>1001002</th>\n      <th>1001003</th>\n      <th>1020002</th>\n      <th>1020003</th>\n      <th>1021001</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979-01-01</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10.177674</td>\n      <td>10.939560</td>\n      <td>10.132287</td>\n      <td>10.424700</td>\n      <td>10.716425</td>\n      <td>11.585810</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979-01-02</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>2</td>\n      <td>10.073322</td>\n      <td>10.855575</td>\n      <td>9.982770</td>\n      <td>10.489676</td>\n      <td>10.810094</td>\n      <td>11.818355</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979-01-03</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>3</td>\n      <td>10.978896</td>\n      <td>11.760256</td>\n      <td>10.890517</td>\n      <td>11.500134</td>\n      <td>11.781082</td>\n      <td>12.665569</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979-01-04</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>4</td>\n      <td>8.506858</td>\n      <td>9.651696</td>\n      <td>8.612532</td>\n      <td>8.862529</td>\n      <td>9.321736</td>\n      <td>10.355026</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979-01-05</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>5</td>\n      <td>10.356481</td>\n      <td>11.121019</td>\n      <td>10.359378</td>\n      <td>10.481868</td>\n      <td>10.799477</td>\n      <td>11.235866</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n4.1.3. Minimum Temperature filter The same process is repeated as with the maximum temperature.\n\n::: {#tbl-polar-2 .cell tbl-cap='Minimum temperature filter for the stations in each basin' execution_count=12}\n``` {.python .cell-code}\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/tmin_cr2met_C_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'tmin.csv'), index=False)\n\nprint(\"Filtered columns and new file of minimum temperatures for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiltered columns and new file of minimum temperatures for the basin's stations saved.\nPreview:\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>1001001</th>\n      <th>1001002</th>\n      <th>1001003</th>\n      <th>1020002</th>\n      <th>1020003</th>\n      <th>1021001</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979-01-01</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-5.849425</td>\n      <td>-5.033302</td>\n      <td>-5.138722</td>\n      <td>-5.704229</td>\n      <td>-5.709160</td>\n      <td>-5.510278</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979-01-02</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>2</td>\n      <td>-5.765660</td>\n      <td>-4.986696</td>\n      <td>-5.135554</td>\n      <td>-5.446885</td>\n      <td>-5.443863</td>\n      <td>-5.084203</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979-01-03</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>3</td>\n      <td>-5.718315</td>\n      <td>-4.929108</td>\n      <td>-5.020927</td>\n      <td>-5.438698</td>\n      <td>-5.442942</td>\n      <td>-5.027288</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979-01-04</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>4</td>\n      <td>-3.798310</td>\n      <td>-2.945276</td>\n      <td>-3.108570</td>\n      <td>-4.030442</td>\n      <td>-3.834039</td>\n      <td>-3.309620</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979-01-05</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>5</td>\n      <td>-4.913381</td>\n      <td>-4.138040</td>\n      <td>-4.194681</td>\n      <td>-4.774841</td>\n      <td>-4.826542</td>\n      <td>-4.284366</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n4.1.4. Precipitation filter The same process is repeated.\n\n::: {#tbl-polar-3 .cell tbl-cap='Precipitation filter for the stations in each basin' execution_count=13}\n``` {.python .cell-code}\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/precip_cr2met_mm_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'pp.csv'), index=False)\n\nprint(\"Filtered columns and new file of precipitation for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiltered columns and new file of precipitation for the basin's stations saved.\nPreview:\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>1001001</th>\n      <th>1001002</th>\n      <th>1001003</th>\n      <th>1020002</th>\n      <th>1020003</th>\n      <th>1021001</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979-01-01</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3.830792</td>\n      <td>2.995933</td>\n      <td>4.351452</td>\n      <td>2.620128</td>\n      <td>1.811431</td>\n      <td>0.376418</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979-01-02</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979-01-03</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.033105</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979-01-04</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2.855784</td>\n      <td>2.070867</td>\n      <td>2.963318</td>\n      <td>3.065628</td>\n      <td>2.160813</td>\n      <td>1.676861</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979-01-05</td>\n      <td>1979</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n4.1.5. Streamflow filter The same process is repeated.\n\n::: {#tbl-polar-4 .cell tbl-cap='Streamflow filter for the stations in each basin' execution_count=14}\n``` {.python .cell-code}\ndf = pd.read_csv(os.path.join(ruta_base, 'CAMELS_CL_v202201/q_m3s_day.csv'))\n\ncolumnas_filtradas = [col for col in df.columns if col.isdigit() and 9400000 <= int(col) <= 9499999]\ncolumnas_filtradas += [col for col in columnas_adicionales if col in df.columns]\n\ndf_filtrado = df[columnas_filtradas]\n\ndf_filtrado.to_csv(os.path.join(ruta_guardado, 'q.csv'), index=False)\n\nprint(\"Filtered columns and new file of streamflow for the basin's stations saved.\")\n\nprint(\"Preview:\")\ndf.iloc[:5, :10]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiltered columns and new file of streamflow for the basin's stations saved.\nPreview:\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>1001001</th>\n      <th>1001002</th>\n      <th>1001003</th>\n      <th>1020002</th>\n      <th>1020003</th>\n      <th>1021001</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1900-01-01</td>\n      <td>1900</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1900-01-02</td>\n      <td>1900</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1900-01-03</td>\n      <td>1900</td>\n      <td>1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1900-01-04</td>\n      <td>1900</td>\n      <td>1</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1900-01-05</td>\n      <td>1900</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Create separate CSV files for each station and variable\n\n4.2.1. Minimum Temperature 4.2.1.1. CSV file path\n\n::: {#1513900f .cell execution_count=15}\n``` {.python .cell-code}\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmin.csv'\n```\n:::\n\n\n4.2.1.2. Read CSV file\n\n::: {#f1477e0f .cell execution_count=16}\n``` {.python .cell-code}\ndf = pd.read_csv(archivo_csv)\n```\n:::\n\n\n4.2.1.3. Get the Data Frame columns\n\n::: {#6cbbb13f .cell execution_count=17}\n``` {.python .cell-code}\ncolumnas = df.columns\n```\n:::\n\n\n4.2.1.4. Create a directory to save files by column\n\n::: {#09169a24 .cell execution_count=18}\n``` {.python .cell-code}\noutput_dir = 'Hidroclima/Base de datos/1.temperaturas_min'\nos.makedirs(output_dir, exist_ok=True)\n```\n:::\n\n\n4.2.1.5. Iterate over the columns and save the data for `year`, `month,` and `day`\n\n::: {#tbl-polar-5 .cell tbl-cap='Daily minimum temperature for station 9437002' execution_count=19}\n``` {.python .cell-code}\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmin'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n    \nprint(\"Files of minimum temperature (tmin) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiles of minimum temperature (tmin) separated by station were successfully generated.\nGenerated_files:\n['.DS_Store', '9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9437002.csv\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>tmin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5.023806</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4.801817</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6.695025</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>4</td>\n      <td>6.986356</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>5</td>\n      <td>7.612088</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n4.2.2. Maximum Temperature The same process is repeated\n\n::: {#tbl-polar-6 .cell tbl-cap='Daily maximum temperature for station 9437002' execution_count=20}\n``` {.python .cell-code}\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/tmax.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/2.temperaturas_max'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'tmax'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of maximum temperature (tmax) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiles of maximum temperature (tmax) separated by station were successfully generated.\nGenerated_files:\n['9116001.csv', '9104001.csv', '9104002.csv', '.DS_Store', '9122002.csv', '9106001.csv', '9437002.csv', '9433001.csv', '9405001.csv', '9134001.csv', '9126001.csv', '9102001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9140001.csv', '9123001.csv', '9131001.csv', '9107001.csv', '9436001.csv', '9400000.csv', '9107002.csv', '9412001.csv', '9111001.csv', 'month.csv', 'day.csv', '9135001.csv', '9127001.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9101002.csv', '9414001.csv', '9129002.csv', '9101001.csv', '9113001.csv']\nFirst file: station 9104001.csv\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>tmax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>1</td>\n      <td>21.707890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>2</td>\n      <td>24.050957</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>3</td>\n      <td>24.525264</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>4</td>\n      <td>26.103316</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>5</td>\n      <td>25.903262</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n4.2.3. Precipitation The same process is repeated\n\n::: {#tbl-polar-7 .cell tbl-cap='Daily precipitation for station 9437002' execution_count=21}\n``` {.python .cell-code}\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/pp.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/3.precipitaciones'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'pp'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of precipitation (pp) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiles of precipitation (pp) separated by station were successfully generated.\nGenerated_files:\n['.DS_Store', '9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9437002.csv\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>pp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1979</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n4.2.4. Streamflow The same process is repeated\n\n::: {#tbl-polar-8 .cell tbl-cap='Daily streamflow for station 9437002' execution_count=22}\n``` {.python .cell-code}\narchivo_csv = 'Hidroclima/Base de datos/0.filtrado_estaciones/q.csv'\n\ndf = pd.read_csv(archivo_csv)\n\ncolumnas = df.columns\n\noutput_dir = 'Hidroclima/Base de datos/7.caudales'\nos.makedirs(output_dir, exist_ok=True)\n\nfor col in columnas:\n    df_col = df[['year', 'month', 'day', col]].copy()\n    df_col = df_col.rename(columns={col: 'q'})\n    \n    output_path = os.path.join(output_dir, f'{col}.csv')\n    df_col.to_csv(output_path, index=False)\n\nprint(\"Files of streamflow (q) separated by station were successfully generated.\")\n\narchivos_generados = os.listdir(output_dir)\nprint(\"Generated_files:\")\nprint(archivos_generados)\n\nprimer_archivo = archivos_generados[1]\nruta_primero = os.path.join(output_dir, primer_archivo)\n\ndf_primero = pd.read_csv(ruta_primero)\nprint(f\"First file: station {primer_archivo}\")\ndisplay(df_primero.head())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiles of streamflow (q) separated by station were successfully generated.\nGenerated_files:\n['.DS_Store', '9437002.csv', '9433001.csv', '9405001.csv', '9423001.csv', '9434001.csv', 'year.csv', '9402001.csv', '9436001.csv', '9400000.csv', '9412001.csv', 'month.csv', 'day.csv', '9416001.csv', '9404001.csv', '9420001.csv', '9414001.csv']\nFirst file: station 9437002.csv\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>q</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1900</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1900</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1900</td>\n      <td>1</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1900</td>\n      <td>1</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1900</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Split data by station\n\n4.3.1. Format data for compability with Climpact 4.3.1.1. Mapping precipitation, minimum and maximum temperature based on filename and file path\n\n::: {#6c856940 .cell execution_count=23}\n``` {.python .cell-code}\ndir_principal = 'Hidroclima/Base de datos'\n\nsubcarpetas = ['1.temperaturas_min', '2.temperaturas_max', '3.precipitaciones']\n\ncolumna_map = {\n    '1.temperaturas_min': 'tmin',\n    '2.temperaturas_max': 'tmax',\n    '3.precipitaciones': 'prcp'\n}\n\ndef obtener_archivos(subcarpeta):\n    ruta_subcarpeta = os.path.join(dir_principal, subcarpeta)\n    archivos = [archivo for archivo in os.listdir(ruta_subcarpeta) if archivo.endswith('.csv') and archivo not in ['year.csv', 'month.csv', 'day.csv']]\n    return archivos\n\ndef leer_archivo(ruta, columna):\n    df = pd.read_csv(ruta)\n    df = df.rename(columns={df.columns[-1]: columna})\n    return df\n\nestaciones_data = {}\n\nfor subcarpeta in subcarpetas:\n    columna = columna_map[subcarpeta]\n    archivos = obtener_archivos(subcarpeta)\n    \n    for archivo in archivos:\n        estacion = os.path.splitext(archivo)[0]\n        ruta_archivo = os.path.join(dir_principal, subcarpeta, archivo)\n        \n        df = leer_archivo(ruta_archivo, columna)\n        \n        if estacion not in estaciones_data:\n            estaciones_data[estacion] = df[['year', 'month', 'day', columna]]\n        else:\n            estaciones_data[estacion] = estaciones_data[estacion].merge(df[['year', 'month', 'day', columna]], on=['year', 'month', 'day'], how='outer')\n```\n:::\n\n\n4.3.1.2. Save files by station\n\n::: {#22e6312b .cell execution_count=24}\n``` {.python .cell-code}\noutput_dir = os.path.join(dir_principal, '4.pre_Climpact')\nos.makedirs(output_dir, exist_ok=True)\n\nfor estacion, df in estaciones_data.items():\n    for columna in ['prcp', 'tmax', 'tmin']:\n        if columna not in df.columns:\n            df[columna] = pd.NA\n    \n    df = df[['year', 'month', 'day', 'prcp', 'tmax', 'tmin']]\n```\n:::\n\n\n4.3.1.3. Format:\n\n-   Approximate variable values to 1 decimal place\n\n-   Convert `day`and `month` values to 2 digits\n\n-   Combine `year`, `month` and `day` into a single 'date' column\n\n-   Replace `inf`, `-inf` and `NaN` values ​​with `-99.9`\n\n-   Export as a `.txt` file\n\n-   Correct order of columns\n\n::: {#tbl-polar-9 .cell tbl-cap='List of the generated files in the output directory' execution_count=25}\n``` {.python .cell-code}\n    df[['prcp', 'tmax', 'tmin']] = df[['prcp', 'tmax', 'tmin']].apply(lambda x: round(x, 1))\n    \n    df['month'] = df['month'].apply(lambda x: f'{x:02}')\n    df['day'] = df['day'].apply(lambda x: f'{x:02}')\n    \n    df['fecha'] = df.apply(lambda row: f\"{int(row['year']):4d} {row['month']} {row['day']}\", axis=1)\n    \n    df = df.replace([float('inf'), float('-inf')], -99.9).fillna(-99.9)\n    \n    ruta_salida = os.path.join(output_dir, f'{estacion}.txt')\n    \n    with open(ruta_salida, 'w') as f:\n        for _, row in df.iterrows():\n            f.write(f\"{row['fecha']}    {row['prcp']:5.1f}     {row['tmax']:4.1f}     {row['tmin']:4.1f}\\n\")\n\nprint(\"Files for Climpact generated successfully.\")\n\narchivos_generados = sorted(os.listdir(output_dir))\ndf_archivos = pd.DataFrame(archivos_generados, columns=['Generated files'])\ndisplay(df_archivos)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiles for Climpact generated successfully.\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Generated files</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.DS_Store</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9113001.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9400000.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9402001.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9404001.txt</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>9405001.txt</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9412001.txt</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>9414001.txt</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9416001.txt</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9420001.txt</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>9423001.txt</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>9433001.txt</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>9434001.txt</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>9436001.txt</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>9437002.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#tbl-polar-10 .cell tbl-cap='Station 9437002 file with information on each variable' execution_count=26}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<table border=\"1\" class=\"dataframe\">\n  <tbody>\n    <tr>\n      <td>1900</td>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1</td>\n      <td>3</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1</td>\n      <td>4</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>1</td>\n      <td>5</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n```\n:::\n:::\n\n\n4.3.2. Format data for compability with IHA 4.3.2.1. The same process is repeated, now for the streamflow.\n\n::: {#58dfdc88 .cell execution_count=27}\n``` {.python .cell-code}\ndir_entrada = os.path.join('Hidroclima', 'Base de datos', '7.caudales')\ndir_salida = os.path.join('Hidroclima', 'Base de datos', '8.pre_IHA')\n\nos.makedirs(dir_salida, exist_ok=True)\n\nfor archivo in os.listdir(dir_entrada):\n    if archivo.endswith('.csv'):\n        ruta_entrada = os.path.join(dir_entrada, archivo)\n        \n        archivo_salida = os.path.splitext(archivo)[0] + '.txt'\n        ruta_salida = os.path.join(dir_salida, archivo_salida)\n\n        df = pd.read_csv(ruta_entrada)\n\n        columnas_requeridas = {'year', 'month', 'day', 'q'}\n        if not columnas_requeridas.issubset(df.columns):\n            print(f\"The {archivo} file does not contain the required columns: {columnas_requeridas}\")\n            continue\n\n        df = df[['year', 'month', 'day', 'q']]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe year.csv file does not contain the required columns: {'month', 'day', 'q', 'year'}\nThe month.csv file does not contain the required columns: {'month', 'day', 'q', 'year'}\nThe day.csv file does not contain the required columns: {'month', 'day', 'q', 'year'}\n```\n:::\n:::\n\n\n4.3.2.2. Format:\n\n-   Aproximate streamflow values to 1 decimal place\n\n-   Date column in **YYYY-MM-DD** format\n\n-   Replace `inf`, `-inf`, and `NaN` values ​​with `-1.0`\n\n-   Delete leading rows where 'q' equals -1.0\n\n-   Streamflow column named `flow`\n\n-   Export as `.txt`file\n\n::: {#770541ff .cell execution_count=28}\n``` {.python .cell-code}\n        df = df.replace([float('inf'), float('-inf')], -1.0).fillna(-1.0)\n\n        df = df.loc[df['q'] != -1.0].reset_index(drop=True)\n\n        df['q'] = df['q'].round(1)\n\n        df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n\n        df = df[['date', 'q']].rename(columns={'q': 'flow'})\n\n        df.to_csv(ruta_salida, index=False, header=True)\n\nprint(\"IHA files processed successfully.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIHA files processed successfully.\n```\n:::\n:::\n\n\n### Extra files and folders for sorting results\n\n4.4.1. List of folders to create:\n\n-   Folder 5 stores the station-specific folders generated by Climpact.\n\n-   Folder 6 contains customized plots based on Climpact results.\n\n-   Folder 9 stores the Excel files generated by IHA for each station, along with their processed CSV versions.\n\n-   Folder 10 includes the figures created from IHA data.\n\n-   Folder 11 contains text files intended to be imported into QGIS for georeferencing.\n\n::: {#01f8d7fd .cell execution_count=29}\n``` {.python .cell-code}\nruta_base = os.path.join('Hidroclima', 'Base de datos')\n\ncarpetas = [\n    '5.Climpact',\n    '6.Figuras_Climpact',\n    '9.IHA',\n    '10.Figuras_IHA',\n    '11.Georreferenciación'\n]\n\nfor carpeta in carpetas:\n    ruta_carpeta = os.path.join(ruta_base, carpeta)\n    os.makedirs(ruta_carpeta, exist_ok=True)\n    print(f\"Folder created: {ruta_carpeta}\")\n\nprint(\"All necessary folders for the results have been created successfully.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFolder created: Hidroclima/Base de datos/5.Climpact\nFolder created: Hidroclima/Base de datos/6.Figuras_Climpact\nFolder created: Hidroclima/Base de datos/9.IHA\nFolder created: Hidroclima/Base de datos/10.Figuras_IHA\nFolder created: Hidroclima/Base de datos/11.Georreferenciación\nAll necessary folders for the results have been created successfully.\n```\n:::\n:::\n\n\n4.4.2. Georeference the stations in the study basin\n\n::: {#tbl-polar-11 .cell tbl-cap='Information by georeferenced station' execution_count=30}\n``` {.python .cell-code}\narchivo_entrada = \"Hidroclima/Base de datos/CAMELS_CL_v202201/catchment_attributes.csv\"\ndf = pd.read_csv(archivo_entrada)\n\ndf_filtrado = df[(df['gauge_id'] >= 9400000) & (df['gauge_id'] <= 9499999)]\n\ndf_filtrado = df_filtrado[['gauge_id', 'gauge_name', 'gauge_lat', 'gauge_lon', 'record_period_start', 'record_period_end']]\n\ndirectorio_salida = \"Hidroclima/Base de datos/11.Georreferenciación/Estaciones.csv\"\n\ndf_filtrado.to_csv(directorio_salida, index=False)\n\nprint(\"Filtered file saved as:\", directorio_salida)\n\nfrom IPython.display import display\ndisplay(df_filtrado)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFiltered file saved as: Hidroclima/Base de datos/11.Georreferenciación/Estaciones.csv\n```\n:::\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>gauge_id</th>\n      <th>gauge_name</th>\n      <th>gauge_lat</th>\n      <th>gauge_lon</th>\n      <th>record_period_start</th>\n      <th>record_period_end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>370</th>\n      <td>9400000</td>\n      <td>Rio Truful En Camino Internacional</td>\n      <td>-38.8444</td>\n      <td>-71.6536</td>\n      <td>2014-12-18</td>\n      <td>2020-03-24</td>\n    </tr>\n    <tr>\n      <th>371</th>\n      <td>9402001</td>\n      <td>Rio Allipen En Melipeuco</td>\n      <td>-38.8653</td>\n      <td>-71.7336</td>\n      <td>1985-01-17</td>\n      <td>2019-08-31</td>\n    </tr>\n    <tr>\n      <th>372</th>\n      <td>9404001</td>\n      <td>Rio Allipen En Los Laureles</td>\n      <td>-38.9833</td>\n      <td>-72.2333</td>\n      <td>1946-03-18</td>\n      <td>2019-11-10</td>\n    </tr>\n    <tr>\n      <th>373</th>\n      <td>9405001</td>\n      <td>Rio Curaco En Colico</td>\n      <td>-39.0333</td>\n      <td>-72.0833</td>\n      <td>1986-10-31</td>\n      <td>2019-03-27</td>\n    </tr>\n    <tr>\n      <th>374</th>\n      <td>9412001</td>\n      <td>Rio Trancura En Curarrehue</td>\n      <td>-39.3600</td>\n      <td>-71.5808</td>\n      <td>1968-09-01</td>\n      <td>2020-04-07</td>\n    </tr>\n    <tr>\n      <th>375</th>\n      <td>9414001</td>\n      <td>Rio Trancura Antes Rio Llafenco</td>\n      <td>-39.3333</td>\n      <td>-71.7667</td>\n      <td>1970-10-01</td>\n      <td>2019-08-31</td>\n    </tr>\n    <tr>\n      <th>376</th>\n      <td>9416001</td>\n      <td>Rio Liucura En Liucura</td>\n      <td>-39.2561</td>\n      <td>-71.8244</td>\n      <td>1971-10-01</td>\n      <td>2019-04-29</td>\n    </tr>\n    <tr>\n      <th>377</th>\n      <td>9420001</td>\n      <td>Rio Tolten En Villarica</td>\n      <td>-39.2667</td>\n      <td>-72.2333</td>\n      <td>1929-03-05</td>\n      <td>2020-03-01</td>\n    </tr>\n    <tr>\n      <th>378</th>\n      <td>9423001</td>\n      <td>Rio Tolten En Coipue</td>\n      <td>-39.1000</td>\n      <td>-72.3833</td>\n      <td>1929-12-16</td>\n      <td>2020-03-25</td>\n    </tr>\n    <tr>\n      <th>379</th>\n      <td>9433001</td>\n      <td>Rio Puyehue En Quitratue</td>\n      <td>-39.1500</td>\n      <td>-72.6667</td>\n      <td>1947-10-07</td>\n      <td>2019-08-31</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>9434001</td>\n      <td>Rio Donguil En Gorbea</td>\n      <td>-39.1000</td>\n      <td>-72.6833</td>\n      <td>1947-10-06</td>\n      <td>2019-08-31</td>\n    </tr>\n    <tr>\n      <th>381</th>\n      <td>9436001</td>\n      <td>Rio Mahuidanche En Santa Ana</td>\n      <td>-39.0833</td>\n      <td>-72.9333</td>\n      <td>1987-03-17</td>\n      <td>2019-04-30</td>\n    </tr>\n    <tr>\n      <th>382</th>\n      <td>9437002</td>\n      <td>Rio Tolten En Teodoro Schmidt</td>\n      <td>-39.0144</td>\n      <td>-73.0828</td>\n      <td>1991-02-12</td>\n      <td>2020-04-07</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n## Generation of figures for climate indicators script\n\nBy default, Climpact generates figures for each calculated indicator at each station. However, the following script provides a general framework for creating customized figures.\n\n### General framework for customized figures\n\n5.1.1. Libraries.\n\n::: {#8a40c3f1 .cell execution_count=31}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom scipy.stats import linregress\n```\n:::\n\n\n5.1.2. Base route and output route.\n\nIn this case, the figure of the annual accumulated precipitation indicator is generated.\n\n::: {#d9550423 .cell execution_count=32}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n```\n:::\n\n\n5.1.3. Selecting the indicator to be graphed.\n\nIn this case, the annual total precipitation indicator is used, identified as `prcptot` in the dataset and therefore with its corresponding station code followed by `_prcptot_ANN.csv` in its file name. To select a different indicator, simply use the name of the corresponding file that contains the desired variable, for example, `_txx_ANN.csv` and the `txx` variable for monthly maximum daily temperature.\n\n::: {#7546ffcb .cell execution_count=33}\n``` {.python .cell-code}\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n```\n:::\n\n\n5.1.4. Create the figure.\n\nThe use of Sen's slope, the regression line, and the statistical values calculated by the Climpact software have not yet been systematically included in the figure.\n\n::: {#cell-fig-polar-1 .cell execution_count=34}\n``` {.python .cell-code}\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Annual precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n        \n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of total accumulated precipitation at station 9434001](indicadores_files/figure-html/fig-polar-1-output-1.png){#fig-polar-1 width=1072 height=717}\n:::\n:::\n\n\n### Suggested precipitation indicators and their figures\n\n5.2.1. Precipitation intensity (sdii).\n\nAnnual total precipitation divided by the number of wet days (when total precipitation \\>= 1.0 mm) is now graphed for each station.\n\n::: {#cell-fig-polar-2 .cell execution_count=35}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_sdii_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'sdii']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['sdii'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['sdii'], marker='D', linestyle='-', color='black', label='Precipitation intensity')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['sdii'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation intensity\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_sdii_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of precipitation intensity at station 9423001](indicadores_files/figure-html/fig-polar-2-output-1.png){#fig-polar-2 width=1077 height=717}\n:::\n:::\n\n\n5.2.2. Anual accumulated precipitation (prcptot).\n\nAnnual sum of daily precipitation \\>= 1.0 mm is now graphed for each station. This was already calculated above.\n\n::: {#cell-fig-polar-3 .cell execution_count=36}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\ncontador = 0\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_prcptot_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'prcptot']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['prcptot'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['prcptot'], marker='D', linestyle='-', color='black', label='Total Precipitation')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['prcptot'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Anual precipitation\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Precipitation (mm)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_prcptot_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of total accumulated precipitation at station 9423001](indicadores_files/figure-html/fig-polar-3-output-1.png){#fig-polar-3 width=1072 height=717}\n:::\n:::\n\n\n5.2.3. Consecutive dry days (cdd).\n\nMaximum annual number of consecutive dry days (when precipitation \\< 1.0 mm).\n\n::: {#cell-fig-polar-4 .cell execution_count=37}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_cdd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'cdd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['cdd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['cdd'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['cdd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Consecutive dry days\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_cdd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of consecutive dry days at station 9423001](indicadores_files/figure-html/fig-polar-4-output-1.png){#fig-polar-4 width=1078 height=717}\n:::\n:::\n\n\n5.2.4. Days with precipitation greater than 30mm (r30mm).\n\nNumber of days when precipitation \\>= 30mm.\n\n::: {#cell-fig-polar-5 .cell execution_count=38}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_r30mm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'r30mm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['r30mm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['r30mm'], marker='D', linestyle='-', color='black', label='Dry days')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['r30mm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Precipitation >= 30mm\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_r30mm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of days with precipitation greater than 30 mm at station 9423001](indicadores_files/figure-html/fig-polar-5-output-1.png){#fig-polar-5 width=1079 height=717}\n:::\n:::\n\n\n5.2.5. Standardised Precipitation Evapotranspiration Index (SPEI)\n\nThis indicator estimates water balance using precipitation and temperature information. It provides a drought indicator. In this case, it is graphed on a 24-month scale. Due to the monthly scale of the indicator, the code has slight adjustments.\n\n::: {#cell-fig-polar-6 .cell execution_count=39}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Precipitation'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_24month_spei_MON.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'spei']]\n\n        df['time'] = pd.to_datetime(df['time'], format='%Y-%m')\n\n        df = df[df['spei'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n\n        df_pos = df[df['spei'] >= 0]\n        df_neg = df[df['spei'] < 0]\n\n        plt.plot(df.index, df['spei'], linestyle='-', color='black', label='SPEI')\n\n        plt.plot(df_pos.index, df_pos['spei'], marker='o', linestyle='None', color='black', label='SPEI ≥ 0')\n\n        plt.plot(df_neg.index, df_neg['spei'], marker='o', linestyle='None', color='gray', label='SPEI < 0')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['spei'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - SPEI compared to the last 24 months\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('SPEI', fontsize=24, fontname='Times New Roman')\n\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.1, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_spei24_MON_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of Standardised Precipitation Evapotrasnpiration Index at station 9423001](indicadores_files/figure-html/fig-polar-6-output-1.png){#fig-polar-6 width=1078 height=717}\n:::\n:::\n\n\n### Suggested temperature indicators and their figures\n\n5.3.1. Annual mean daily minimum temperature (tnm).\n\n::: {#cell-fig-polar-7 .cell execution_count=40}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_tnm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'tnm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['tnm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['tnm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['tnm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily minimum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_tnm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of annual mean daily minimum temperature at station 9423001](indicadores_files/figure-html/fig-polar-7-output-1.png){#fig-polar-7 width=1064 height=717}\n:::\n:::\n\n\n5.3.2. Annual mean daily maximum temperature (txm).\n\n::: {#cell-fig-polar-8 .cell execution_count=41}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txm_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txm']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txm'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txm'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txm'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual mean daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txm_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of annual mean daily maximum temperature at station 9423001](indicadores_files/figure-html/fig-polar-8-output-1.png){#fig-polar-8 width=1076 height=717}\n:::\n:::\n\n\n5.3.3. Annual warmest daily maximum temperature (txx).\n\n::: {#cell-fig-polar-9 .cell execution_count=42}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_txx_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'txx']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['txx'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['txx'], marker='D', linestyle='-', color='black', label='Temperature')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['txx'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Annual warmest daily maximum temperature\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Temperature (ºC)', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_txx_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of annual warmest daily maximum temperature at station 9423001](indicadores_files/figure-html/fig-polar-9-output-1.png){#fig-polar-9 width=1079 height=717}\n:::\n:::\n\n\n5.3.4. Annual number of days when minimum temperature \\< 0ºC (id).\n\n::: {#cell-fig-polar-10 .cell execution_count=43}\n``` {.python .cell-code}\nruta_base = 'Hidroclima/Base de datos/5.Climpact'\nruta_salida_base = 'Hidroclima/Base de datos/6.Figuras_Climpact/Temperature'\nos.makedirs(ruta_salida_base, exist_ok=True)\n\nsubcarpetas = [os.path.join(ruta_base, carpeta) for carpeta in os.listdir(ruta_base) if os.path.isdir(os.path.join(ruta_base, carpeta))]\n\ncontador = 0\n\nfor subcarpeta in subcarpetas:\n    carpeta_indices = os.path.join(subcarpeta, 'indices')\n    if not os.path.exists(carpeta_indices):\n        continue\n\n    archivos = [f for f in os.listdir(carpeta_indices) if f.endswith('_fd_ANN.csv')]\n    for archivo in archivos:\n        ruta_archivo = os.path.join(carpeta_indices, archivo)\n\n        df = pd.read_csv(ruta_archivo, skiprows=6)\n        df.columns = df.columns.str.strip()\n        df = df[['time', 'fd']]\n        df['time'] = pd.to_datetime(df['time'], format='%Y')\n        df = df[df['fd'] != -99.9]\n        df.set_index('time', inplace=True)\n\n        plt.figure(figsize=(12, 8))\n        plt.plot(df.index, df['fd'], marker='D', linestyle='-', color='black', label='Days T<0ºC')\n\n        slope, intercept, r_value, p_value, std_err = linregress(mdates.date2num(df.index), df['fd'])\n        plt.plot(df.index, intercept + slope * mdates.date2num(df.index), linestyle='--', color='black', label='Regression line')\n\n        plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n        titulo = f\"{archivo.split('_')[0]} Station - Days when minimum temperature < 0ºC\"\n        #plt.title(titulo, fontsize=24, fontname='Times New Roman')\n        plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n        plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n        plt.gca().xaxis.set_major_locator(mdates.YearLocator(5))\n        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n        plt.xticks(rotation=45, fontsize=20, fontname='Times New Roman')\n        plt.yticks(fontsize=24, fontname='Times New Roman')\n\n        info_text = (\n            f\"Slope: {slope:.2f}\\n\"\n            f\"Confidence interval: [{intercept - 1.96 * std_err:.2f}, {intercept + 1.96 * std_err:.2f}]\\n\"\n            f\"p-value: {p_value:.3f}\"\n        )\n        plt.text(1.1, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14, verticalalignment='top',\n                 bbox=dict(facecolor='white', alpha=0.5))\n\n        plt.grid(False)\n        plt.legend(bbox_to_anchor=(1.4, 0.4), fontsize=14, frameon=False)\n        plt.tight_layout()\n\n        estacion_codigo = archivo.split('_')[0]\n        ruta_salida_estacion = os.path.join(ruta_salida_base, estacion_codigo)\n        os.makedirs(ruta_salida_estacion, exist_ok=True)\n        ruta_salida = os.path.join(ruta_salida_estacion, f\"{estacion_codigo}_fd_ANN_plot.png\")\n\n        plt.savefig(ruta_salida)\n\n        if contador == 0:\n            plt.show()\n        else:\n            plt.close()\n\n        contador += 1\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of annual numbery of days when minimum temperature is lower than 0ºC at station 9423001](indicadores_files/figure-html/fig-polar-10-output-1.png){#fig-polar-10 width=1079 height=717}\n:::\n:::\n\n\n## Generation of figures for hydrologic indicators script\n\n### Libraries and workspace.\n\n::: {#34545b02 .cell execution_count=44}\n``` {.python .cell-code}\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport csv\nimport matplotlib.pyplot as plt\n\ninput_directory = 'Hidroclima/Base de datos/9.IHA'\n\nsheets_to_convert = ['ann', 'sco', 'lsq', 'pct', 'daily efcs', 'fdc']\n\nfor filename in os.listdir(input_directory):\n    if filename.endswith('.xlsx') or filename.endswith('.xls'):\n        filepath = os.path.join(input_directory, filename)\n        excel_file = pd.ExcelFile(filepath)\n        \n        station_code = os.path.splitext(filename)[0]\n        \n        station_output_directory = os.path.join(input_directory, 'csv', station_code)\n        \n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for sheet in sheets_to_convert:\n            if sheet in excel_file.sheet_names:\n                df = pd.read_excel(filepath, sheet_name=sheet)\n                \n                output_filename = f\"{sheet}_{station_code}.csv\"\n                output_filepath = os.path.join(station_output_directory, output_filename)\n                \n                df.to_csv(output_filepath, index=False)\n                \nprint(\"ann, sco, fdc, pct, lsq and daily efcs files saved in its folder.\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nann, sco, fdc, pct, lsq and daily efcs files saved in its folder.\n```\n:::\n:::\n\n\n### Streamflow figures\n\n6.2.1. Simple monthly median flow for each station\n\nThe order of the months in the `sco_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n::: {#cell-fig-polar-11 .cell execution_count=45}\n``` {.python .cell-code}\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\n\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\nmeses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n\n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            plt.figure(figsize=(12, 8))\n            plt.plot(df_mes.index, df_mes['Median'], marker='.', linestyle='-', color='black', label='Median')\n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Median monthly flow - {station_code} Station', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.grid(True, linestyle='-', linewidth=0.5, color='lightgray')\n            plt.legend(fontsize=14)\n            plt.grid(False)\n\n            output_file = os.path.join(output_dir, f'Median_monthly_flow_{station_code}.png')\n            plt.tight_layout()\n            plt.savefig(output_file, dpi=300)\n            \n            plt.savefig(ruta_salida)\n\n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n\n            contador += 1\n            print(f'Figure saved: {output_file}')\n```\n\n::: {.cell-output .cell-output-display}\n![Indicator of simple monthly median flow at station 9423001](indicadores_files/figure-html/fig-polar-11-output-1.png){#fig-polar-11 width=1098 height=717}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9423001/Median_monthly_flow_9423001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9433001/Median_monthly_flow_9433001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9412001/Median_monthly_flow_9412001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9436001/Median_monthly_flow_9436001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9402001/Median_monthly_flow_9402001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9416001/Median_monthly_flow_9416001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9437002/Median_monthly_flow_9437002.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9405001/Median_monthly_flow_9405001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9420001/Median_monthly_flow_9420001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9414001/Median_monthly_flow_9414001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9404001/Median_monthly_flow_9404001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9434001/Median_monthly_flow_9434001.png\n```\n:::\n:::\n\n\n6.2.2. Boxplot flow for each month calculated from all recorded years for each station\n\nThe language of the months or even the way they are written in the `ann_` file may vary. If so, adjust the `columns` variable and `id_vars` accordingly.\n\n::: {#cell-fig-polar-12 .cell execution_count=46}\n``` {.python .cell-code}\nbase_directory = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = os.path.join('Hidroclima/Base de datos/10.Figuras_IHA', 'Caudal')\nif not os.path.exists(output_root_directory):\n    os.makedirs(output_root_directory)\n\ncontador = 0\n\nfor station_folder in os.listdir(base_directory):\n    station_path = os.path.join(base_directory, station_folder)\n    if os.path.isdir(station_path):\n        station_output_directory = os.path.join(output_root_directory, station_folder)\n        if not os.path.exists(station_output_directory):\n            os.makedirs(station_output_directory)\n        \n        for filename in os.listdir(station_path):\n            if filename.startswith('ann_') and filename.endswith('.csv'):\n                input_file = os.path.join(station_path, filename)\n                \n                df = pd.read_csv(input_file, skiprows=4)\n                \n                columns = ['Year', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n                df = df[columns]\n\n                df_melted = df.melt(id_vars=['Year'], var_name='Month', value_name='Value')\n                \n                month_translation = {\n                    'January': 'January', 'February': 'February', 'March': 'March', 'April': 'April', \n                    'May': 'May', 'June': 'June', 'July': 'July', 'August': 'August', \n                    'September': 'September', 'October': 'October', 'November': 'November', \n                    'December': 'December'\n                }\n\n                df_melted['Month'] = df_melted['Month'].map(month_translation)\n                \n                plt.rcParams[\"font.family\"] = \"Times New Roman\"\n                plt.rcParams[\"font.size\"] = 12\n                plt.rcParams[\"axes.titlesize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"axes.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"xtick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                plt.rcParams[\"ytick.labelsize\"] = plt.rcParams[\"font.size\"] + 4\n                \n                plt.figure(figsize=(12, 6))\n                sns.boxplot(\n                    x='Month', y='Value', data=df_melted,\n                    order=['January', 'February', 'March', 'April', 'May', 'June', 'July', \n                           'August', 'September', 'October', 'November', 'December'],\n                    color='gray'\n                )\n                #plt.title(f'Distribution of the median monthly flow - {station_folder} Station')\n                plt.xlabel('Month')\n                plt.ylabel('Flow (m3/s)')\n                plt.xticks(rotation=45)\n                plt.tight_layout()\n                \n                output_plot_path = os.path.join(station_output_directory, f'BOXPLOT_{filename[:-4]}.png')\n                plt.savefig(output_plot_path, dpi=300)\n                \n                if contador == 0:\n                    plt.show()\n                else:\n                    plt.close()\n\n                contador += 1\n                \n                print(f'Boxplot saved: {output_plot_path}')\n```\n\n::: {.cell-output .cell-output-display}\n![Boxplot of flow at station 9423001](indicadores_files/figure-html/fig-polar-12-output-1.png){#fig-polar-12 width=1135 height=559}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9423001/BOXPLOT_ann_9423001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9433001/BOXPLOT_ann_9433001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9412001/BOXPLOT_ann_9412001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9436001/BOXPLOT_ann_9436001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9402001/BOXPLOT_ann_9402001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9416001/BOXPLOT_ann_9416001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9437002/BOXPLOT_ann_9437002.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9405001/BOXPLOT_ann_9405001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9420001/BOXPLOT_ann_9420001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9414001/BOXPLOT_ann_9414001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9404001/BOXPLOT_ann_9404001.png\nBoxplot saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9434001/BOXPLOT_ann_9434001.png\n```\n:::\n:::\n\n\n6.2.3. Figure with the percentiles of monthly flows for all years evaluated by station.\n\nThe order of the months in the `pct_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n::: {#cell-fig-polar-13 .cell execution_count=47}\n``` {.python .cell-code}\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"pct_\") and file.endswith(\".csv\"):\n            pct_file = os.path.join(root, file)\n            \n            station_code = os.path.basename(root)\n            \n            station_output_directory = os.path.join(output_root_directory, station_code)\n            \n            if not os.path.exists(station_output_directory):\n                print(f\"Error: The output directory for station {station_code} does not exist.\")\n                continue\n            \n            df = pd.read_csv(pct_file, skiprows=8, header=None) \n            df_mes = df.iloc[:12, :6]\n            df_mes.columns = ['Month', '10%', '25%', '50%', '75%', '90%']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            \n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            plt.figure(figsize=(12, 8))\n            linestyles = ['-', '--', '-.', ':', (0, (1, 10))]\n            marcadores = ['o', 's', '^', 'D', '*']\n            \n            for percentil, linestyle, marcador in zip(['10%', '25%', '50%', '75%', '90%'], linestyles, marcadores):\n                plt.plot(df_mes.index, df_mes[percentil], marker=marcador, linestyle=linestyle, label=percentil, color='black')\n            \n            plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n            #plt.title(f'Percentiles of monthly flows for {station_code}', fontsize=24, fontname='Times New Roman')\n            plt.xlabel('Month', fontsize=24, fontname='Times New Roman')\n            plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n            plt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\n            plt.yticks(fontsize=24, fontname='Times New Roman')\n            plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14)\n            plt.grid(False)\n            plt.tight_layout()\n            \n            output_plot_path = os.path.join(station_output_directory, f'percentiles_{station_code}.png')\n            plt.savefig(output_plot_path, dpi=300)\n            \n            if contador == 0:\n                plt.show()\n            else:\n                plt.close()\n            \n            contador += 1\n            \n            print(f'Figure saved: {output_plot_path}')\n```\n\n::: {.cell-output .cell-output-display}\n![Percentiles of monthly flows at station 9423001](indicadores_files/figure-html/fig-polar-13-output-1.png){#fig-polar-13 width=1029 height=718}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9423001/percentiles_9423001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9433001/percentiles_9433001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9412001/percentiles_9412001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9436001/percentiles_9436001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9402001/percentiles_9402001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9416001/percentiles_9416001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9437002/percentiles_9437002.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9405001/percentiles_9405001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9420001/percentiles_9420001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9414001/percentiles_9414001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9404001/percentiles_9404001.png\nFigure saved: Hidroclima/Base de datos/10.Figuras_IHA/Caudal/9434001/percentiles_9434001.png\n```\n:::\n:::\n\n\n6.2.4. Graphs for each station with the probability of exceedance for each month and at an annual level.\n\nThe language of the months or even the way they are written in the `fdc_` file may vary. If so, adjust the `meses` variable accordingly.\n\n::: {#cell-fig-polar-14 .cell execution_count=48}\n``` {.python .cell-code}\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\noutput_root_directory = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\n\ncontador = 0\n\nmeses = {\n    'Annual': 'Annual', 'January': 'January', 'February': 'February', 'March': 'March',\n    'April': 'April', 'May': 'May', 'June': 'June', 'July': 'July', \n    'August': 'August', 'September': 'September', 'October': 'October', \n    'November': 'November', 'December': 'December'\n}\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"fdc_\") and file.endswith(\".csv\"):\n            fdc_file = os.path.join(root, file)\n            \n            df_headers = pd.read_csv(fdc_file, skiprows=9, nrows=1, header=None)\n            df_data = pd.read_csv(fdc_file, skiprows=11, header=None)\n            \n            col_indices = {}\n            for col_idx, col_name in enumerate(df_headers.iloc[0]):\n                if isinstance(col_name, str) and col_name.strip() in meses:\n                    col_indices[meses[col_name.strip()]] = col_idx\n            \n            station_code = file.split('_')[1].split('.')[0]\n            output_dir = os.path.join(output_root_directory, station_code)\n            if not os.path.exists(output_dir):\n                os.makedirs(output_dir)\n            \n            for mes, mes_label in meses.items():\n                if mes_label in col_indices:\n                    x_col = col_indices[mes_label] + 1\n                    y_col = col_indices[mes_label] \n\n                    data = df_data.iloc[:, [y_col, x_col]].dropna()\n                    data.columns = ['Caudal', 'Probabilidad']\n                    data['Probabilidad'] = data['Probabilidad']\n                    \n                    plt.figure(figsize=(12, 8))\n                    plt.plot(data['Probabilidad'], data['Caudal'], marker='o', linestyle='-', color='black')\n                    #plt.title(f'Flow Duration Curve - {mes_label} ({station_code})', fontsize=16, fontname='Times New Roman')\n                    plt.xlabel('Probability of Exceedance (%)', fontsize=14, fontname='Times New Roman')\n                    plt.ylabel('Flow (m³/s)', fontsize=14, fontname='Times New Roman')\n                    plt.grid(False)\n                    plt.tight_layout()\n                    \n                    output_file = os.path.join(output_dir, f'FDC_{mes_label}_{station_code}.png')\n                    plt.savefig(output_file, dpi=300)\n                    \n                    if contador == 1:\n                        plt.show()\n                    else:\n                        plt.close()\n                        \n                    contador += 1\n                    \nprint('Flow Duration Curve generated for each month of each station')\n```\n\n::: {.cell-output .cell-output-display}\n![Flow Duration Curve for January at station 9423001](indicadores_files/figure-html/fig-polar-14-output-1.png){#fig-polar-14 width=1101 height=716}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nFlow Duration Curve generated for each month of each station\n```\n:::\n:::\n\n\n6.2.5. Figure of the streamflow of all stations present in the basin\n\nThe order of the months in the `sco_` file may vary. If so, adjust the `meses_ingles` variable accordingly.\n\n::: {#cell-fig-polar-15 .cell execution_count=49}\n``` {.python .cell-code}\nbase_path = 'Hidroclima/Base de datos/9.IHA/csv'\nsave_path = 'Hidroclima/Base de datos/10.Figuras_IHA/Caudal'\nos.makedirs(save_path, exist_ok=True)\n\nlinestyles = ['-', '--', '-.', ':', (0, (1, 10)), (0, (5, 10)), (0, (3, 5)), (0, (3, 1)), (0, (5, 3)), (0, (1, 1)), (0, (5, 1)), (0, (1, 5))]\ncolores = ['black', 'darkgray', 'gray', 'lightgray', 'black', 'dimgray', 'gray', 'dimgray', 'darkgray', 'black', 'dimgray', 'black']\nplt.figure(figsize=(12, 8))\nline_counter = 0\n\nfor root, dirs, files in os.walk(base_path):\n    for file in files:\n        if file.startswith(\"sco_\") and file.endswith(\".csv\"):\n            sco_file = os.path.join(root, file)\n            \n            nombre_archivo = os.path.basename(sco_file)\n            codigo_estacion = nombre_archivo.split('_')[1].split('.')[0]\n            \n            df = pd.read_csv(sco_file, skiprows=17, header=None)\n            df_mes = df.iloc[:12, :2]\n            df_mes.columns = ['Month', 'Median']\n            \n            meses_ingles = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n            df_mes['Month'] = meses_ingles\n            df_mes.set_index('Month', inplace=True)\n            \n            linestyle = linestyles[line_counter % len(linestyles)]\n            color = colores[line_counter % len(colores)]\n            plt.plot(df_mes.index, df_mes['Median'], linestyle=linestyle, color=color, label=f'Station {codigo_estacion}')\n            line_counter += 1\n\nplt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n#plt.title('Median monthly flow by station', fontsize=24, fontname='Times New Roman')\nplt.xlabel('Month', fontsize=24, fontname='Times New Roman')\nplt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\nplt.xticks(fontsize=24, fontname='Times New Roman', rotation=45)\nplt.yticks(fontsize=24, fontname='Times New Roman')\nplt.grid(True, linestyle='-', linewidth=0.5, color='black')\nplt.legend(fontsize=14)\nplt.grid(False)\n\nsave_file = os.path.join(save_path, 'qmonthly_TOTstations.png')\nplt.tight_layout()\nplt.savefig(save_file, dpi=300)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Median monthly flow by station](indicadores_files/figure-html/fig-polar-15-output-1.png){#fig-polar-15 width=1098 height=717}\n:::\n:::\n\n\n### Time series figures\n\nThe language of the months, indicator and column of \"year\" or even the way they are written in the `ann_` and `sco_` file may vary.\n\nIf so, adjust:\n\n-   `indicator_names` variable\n\n-   the names for the regression in row `lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]`\n\n-   the `skiprows` variable in `sco_data` with the number of the row where the list of the respective indicator begins\n\n-   the `slope`, `intercept` and `r_squared` variables\n\n6.3.1. Median flow in July over time.\n\nIn this case, the time series of the median flow in July was selected, as it corresponds to the month with the highest flow in the study basin.\n\n6.3.1.1. Reading input files and extracting specific data related to the selected month.\n\n::: {#eee7eea1 .cell execution_count=50}\n``` {.python .cell-code}\nbase_folder_path = 'Hidroclima/Base de datos/9.IHA/csv/'\noutput_folder_path = 'Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/'\nos.makedirs(output_folder_path, exist_ok=True)\n\nindicator_names = {\n    'lsq_row': 'July',              \n    'ann_column': 'July',           \n    'sco_row': 'July',              \n    'plot_label': 'July'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=17, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n:::\n\n\n6.3.1.2. Saving the extracted data in a single `.csv` file.\n\n::: {#dc828fd6 .cell execution_count=51}\n``` {.python .cell-code}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n:::\n\n\n6.3.1.3. Graph format.\n\n::: {#7d45cebd .cell execution_count=52}\n``` {.python .cell-code}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV file and figure for station {station_code} has been saved in {graph_filename}\")\n```\n:::\n\n\n6.3.1.4. Graph generation.\n\n::: {#cell-fig-polar-16 .cell execution_count=53}\n``` {.python .cell-code}\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV file and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/july_9423001.png\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Median flow in July over time at station 9423001](indicadores_files/figure-html/fig-polar-16-output-2.png){#fig-polar-16 width=1024 height=717}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV file and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/july_9433001.png\nThe CSV file and figure for station 9412001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9412001/july_9412001.png\nThe CSV file and figure for station 9436001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9436001/july_9436001.png\nThe CSV file and figure for station 9402001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9402001/july_9402001.png\nThe CSV file and figure for station 9416001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9416001/july_9416001.png\nThe CSV file and figure for station 9437002 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9437002/july_9437002.png\nThe CSV file and figure for station 9405001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9405001/july_9405001.png\nThe CSV file and figure for station 9420001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9420001/july_9420001.png\nThe CSV file and figure for station 9414001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9414001/july_9414001.png\nThe CSV file and figure for station 9404001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9404001/july_9404001.png\nThe CSV file and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/july_9434001.png\n```\n:::\n:::\n\n\n6.3.2. High flow pulses duration by station\n\n6.3.2.1. Reading input files and extracting specific data related to the selected indicator.\n\n::: {#c0b8a116 .cell execution_count=54}\n``` {.python .cell-code}\nindicator_names = {\n    'lsq_row': 'High pulse duration',              \n    'ann_column': 'Hi pulse L',           \n    'sco_row': 'High pulse duration',              \n    'plot_label': 'High pulse duration'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=48, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n:::\n\n\n6.3.2.2. Saving the extracted data in a single `.csv` file.\n\n::: {#f525d028 .cell execution_count=55}\n``` {.python .cell-code}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n:::\n\n\n6.3.2.3. Graph format.\n\n::: {#900d4dd1 .cell execution_count=56}\n``` {.python .cell-code}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Days', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n```\n:::\n\n\n6.3.2.4. Graph generation.\n\n::: {#cell-fig-polar-17 .cell execution_count=57}\n``` {.python .cell-code}\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/high_pulse_duration_9423001.png\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![High flow pulses duration over time at station 9423001](indicadores_files/figure-html/fig-polar-17-output-2.png){#fig-polar-17 width=1029 height=717}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/high_pulse_duration_9433001.png\nThe CSV files and figure for station 9412001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9412001/high_pulse_duration_9412001.png\nThe CSV files and figure for station 9436001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9436001/high_pulse_duration_9436001.png\nThe CSV files and figure for station 9402001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9402001/high_pulse_duration_9402001.png\nThe CSV files and figure for station 9416001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9416001/high_pulse_duration_9416001.png\nThe CSV files and figure for station 9437002 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9437002/high_pulse_duration_9437002.png\nThe CSV files and figure for station 9405001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9405001/high_pulse_duration_9405001.png\nThe CSV files and figure for station 9420001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9420001/high_pulse_duration_9420001.png\nThe CSV files and figure for station 9414001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9414001/high_pulse_duration_9414001.png\nThe CSV files and figure for station 9404001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9404001/high_pulse_duration_9404001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/high_pulse_duration_9434001.png\n```\n:::\n:::\n\n\n6.3.3. Base Flow Index by station\n\n6.3.3.1. Reading input files and extracting specific data related to the selected indicator.\n\n::: {#3f6d8c06 .cell execution_count=58}\n``` {.python .cell-code}\nindicator_names = {\n    'lsq_row': 'Base flow index',              \n    'ann_column': 'Base flow',           \n    'sco_row': 'Base flow index',              \n    'plot_label': 'Base flow index'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=30, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n```\n:::\n\n\n6.3.3.2. Saving the extracted data in a single `.csv` file.\n\n::: {#7202ba91 .cell execution_count=59}\n``` {.python .cell-code}\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n```\n:::\n\n\n6.3.3.3. Graph format.\n\n::: {#af233890 .cell execution_count=60}\n``` {.python .cell-code}\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('BFI', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n```\n:::\n\n\n6.3.3.4. Graph generation.\n\n::: {#cell-fig-polar-18 .cell execution_count=61}\n``` {.python .cell-code}\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/base_flow_index_9423001.png\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Base Flow Index over time at station 9423001](indicadores_files/figure-html/fig-polar-18-output-2.png){#fig-polar-18 width=1032 height=717}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/base_flow_index_9433001.png\nThe CSV files and figure for station 9412001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9412001/base_flow_index_9412001.png\nThe CSV files and figure for station 9436001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9436001/base_flow_index_9436001.png\nThe CSV files and figure for station 9402001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9402001/base_flow_index_9402001.png\nThe CSV files and figure for station 9416001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9416001/base_flow_index_9416001.png\nThe CSV files and figure for station 9437002 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9437002/base_flow_index_9437002.png\nThe CSV files and figure for station 9405001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9405001/base_flow_index_9405001.png\nThe CSV files and figure for station 9420001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9420001/base_flow_index_9420001.png\nThe CSV files and figure for station 9414001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9414001/base_flow_index_9414001.png\nThe CSV files and figure for station 9404001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9404001/base_flow_index_9404001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/base_flow_index_9434001.png\n```\n:::\n:::\n\n\n6.3.4. Small Floods Peaks over time\n\nThe same process is repeated, adjusted to the specific indicator.\n\n::: {#cell-fig-polar-19 .cell execution_count=62}\n``` {.python .cell-code}\nindicator_names = {\n    'lsq_row': 'Small Flood peak',              \n    'ann_column': 'Sfld1 peak',           \n    'sco_row': 'Small Flood peak',              \n    'plot_label': 'Small Flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=80, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 0:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/small_flood_peak_9423001.png\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Small Floods Peaks over time at station 9423001](indicadores_files/figure-html/fig-polar-19-output-2.png){#fig-polar-19 width=1024 height=717}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/small_flood_peak_9433001.png\nThe CSV files and figure for station 9412001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9412001/small_flood_peak_9412001.png\nThe CSV files and figure for station 9436001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9436001/small_flood_peak_9436001.png\nThe CSV files and figure for station 9402001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9402001/small_flood_peak_9402001.png\nThe CSV files and figure for station 9416001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9416001/small_flood_peak_9416001.png\nThe CSV files and figure for station 9437002 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9437002/small_flood_peak_9437002.png\nThe CSV files and figure for station 9405001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9405001/small_flood_peak_9405001.png\nThe CSV files and figure for station 9420001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9420001/small_flood_peak_9420001.png\nThe CSV files and figure for station 9414001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9414001/small_flood_peak_9414001.png\nThe CSV files and figure for station 9404001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9404001/small_flood_peak_9404001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/small_flood_peak_9434001.png\n```\n:::\n:::\n\n\n6.3.4. Large Floods Peaks over time\n\nThe same process is repeated, adjusted to the specific indicator.\n\n::: {#cell-fig-polar-20 .cell execution_count=63}\n``` {.python .cell-code}\nindicator_names = {\n    'lsq_row': 'Large flood peak',              \n    'ann_column': 'Lfld1 peak',           \n    'sco_row': 'Large flood peak',              \n    'plot_label': 'Large flood peak'            \n}\n\ndef extract_data(lsq_file, ann_file, sco_file, indicator):\n    lsq_data = pd.read_csv(lsq_file, skiprows=3)\n    lsq_data.set_index(lsq_data.columns[0], inplace=True)\n    try:\n        lsq_selected = lsq_data.loc[indicator['lsq_row'], ['Slope', 'YInt', 'Sigma', 'Corr', 'PValue', 'FStat', 'R2']]\n    except KeyError:\n        print(f\"Indicator '{indicator['lsq_row']}' not found in lsq_file.\")\n        return None, None, None\n\n    ann_data = pd.read_csv(ann_file, skiprows=4)\n    ann_data.columns = ann_data.columns.str.strip()\n    if indicator['ann_column'] not in ann_data.columns:\n        print(f\"Column '{indicator['ann_column']}' not found in ann_file.\")\n        return None, None, None\n    ann_data = ann_data[['Year', indicator['ann_column']]].dropna()\n\n    sco_data = pd.read_csv(sco_file, skiprows=85, nrows=13, header=None, index_col=0)\n    sco_data.index.name = 'Parameter'\n    sco_data.columns = ['Mediana', 'Coef. Disper.']\n    if indicator['sco_row'] not in sco_data.index:\n        print(f\"Indicator '{indicator['sco_row']}' not found in sco_file.\")\n        return None, None, None\n    sco_selected = sco_data.loc[[indicator['sco_row']]]\n\n    return lsq_selected, ann_data, sco_selected\n\ndef save_to_csv(lsq_data, ann_data, sco_data, output_file):\n    with open(output_file, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        \n        writer.writerow(['Variable', 'Valor'])\n        for idx, value in lsq_data.items():\n            writer.writerow([idx, value])\n        \n        writer.writerow(['Year', indicator_names['ann_column']])\n        for _, row in ann_data.iterrows():\n            writer.writerow([int(row['Year']), row[indicator_names['ann_column']]])\n        \n        writer.writerow(['Mediana', sco_data['Mediana'].values[0]])\n        writer.writerow(['Coef. Disper.', sco_data['Coef. Disper.'].values[0]])\n\ndef plot_data(df, slope, intercept, r_squared, station_code, plot_label):\n    df_anios = df[(df['Variable'].str.isnumeric()) & (df['Valor'].notna())].copy()\n    df_anios['Variable'] = pd.to_numeric(df_anios['Variable'], errors='coerce')\n    df_anios['Valor'] = pd.to_numeric(df_anios['Valor'], errors='coerce')\n    df_anios = df_anios.dropna()\n\n    plt.figure(figsize=(12, 8))\n    plt.plot(df_anios['Variable'], df_anios['Valor'], marker='o', linestyle='None', color='black', label=plot_label)\n    \n    for i in range(1, len(df_anios)):\n        if df_anios['Variable'].iloc[i] - df_anios['Variable'].iloc[i-1] == 1:\n            plt.plot(df_anios['Variable'].iloc[i-1:i+1], df_anios['Valor'].iloc[i-1:i+1], linestyle='-', color='black')\n\n    line = slope * df_anios['Variable'] + intercept\n    plt.plot(df_anios['Variable'], line, linestyle='--', color='black', label='Regression')\n\n    plt.rcParams.update({'font.size': 24, 'font.family': 'Times New Roman'})\n    #plt.title(f'{plot_label} ({station_code})', fontsize=24, fontname='Times New Roman')\n    plt.xlabel('Year', fontsize=24, fontname='Times New Roman')\n    plt.ylabel('Flow (m3/s)', fontsize=24, fontname='Times New Roman')\n    plt.xticks(fontsize=24, fontname='Times New Roman')\n    plt.yticks(fontsize=24, fontname='Times New Roman')\n    plt.legend(bbox_to_anchor=(1.35, 0.95), fontsize=14, frameon=False)\n    plt.grid(False)\n\n    info_text = f'Slope: {slope:.2f}\\nR-Squared: {r_squared:.2f}'\n    plt.text(1.15, 0.65, info_text, transform=plt.gca().transAxes, fontsize=14,\n             verticalalignment='top', horizontalalignment='center',\n             bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.5'))\n\n    station_folder = os.path.join(output_folder_path, station_code)\n    os.makedirs(station_folder, exist_ok=True)\n\n    graph_filename = os.path.join(station_folder, f\"{plot_label.lower().replace(' ', '_')}_{station_code}.png\")\n    plt.tight_layout()\n    plt.savefig(graph_filename)\n\n    print(f\"The CSV files and figure for station {station_code} has been saved in {graph_filename}\")\n\ndef process_all_stations(base_folder_path, output_folder_path, indicator):\n    station_folders = [f for f in os.listdir(base_folder_path) if os.path.isdir(os.path.join(base_folder_path, f))]\n    contador = 0\n    \n    for station_code in station_folders:\n        lsq_file = os.path.join(base_folder_path, station_code, f'lsq_{station_code}.csv')\n        ann_file = os.path.join(base_folder_path, station_code, f'ann_{station_code}.csv')\n        sco_file = os.path.join(base_folder_path, station_code, f'sco_{station_code}.csv')\n\n        if not all(os.path.exists(f) for f in [lsq_file, ann_file, sco_file]):\n            print(f'Missing files for station {station_code}. Skipping station.')\n            continue\n\n        lsq_data, ann_data, sco_data = extract_data(lsq_file, ann_file, sco_file, indicator)\n        if lsq_data is None or ann_data is None or sco_data is None:\n            continue\n\n        output_file = os.path.join(output_folder_path, f\"{indicator['ann_column'].lower()}_{station_code}.csv\")\n        save_to_csv(lsq_data, ann_data, sco_data, output_file)\n\n        try:\n            df = pd.read_csv(output_file, names=['Variable', 'Valor'], skiprows=1)\n        except FileNotFoundError:\n            print(f'File not found: {output_file}')\n            continue\n\n        df = df.dropna()\n\n        try:\n            slope = float(df[df['Variable'] == 'Slope']['Valor'].values[0])\n            intercept = float(df[df['Variable'] == 'YInt']['Valor'].values[0])\n            r_squared = float(df[df['Variable'] == 'R2']['Valor'].values[0])\n        except (IndexError, ValueError) as e:\n            print(f'Error extracting regression values: {e}')\n            continue\n\n        plot_data(df, slope, intercept, r_squared, station_code, indicator['plot_label'])\n        \n        if contador == 2:\n           plt.show()\n        else:\n            plt.close()\n    \n        contador += 1 \n\nprocess_all_stations(base_folder_path, output_folder_path, indicator_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9423001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9423001/large_flood_peak_9423001.png\nThe CSV files and figure for station 9433001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9433001/large_flood_peak_9433001.png\nThe CSV files and figure for station 9412001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9412001/large_flood_peak_9412001.png\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![Large Floods Peaks over time at station 9423001](indicadores_files/figure-html/fig-polar-20-output-2.png){#fig-polar-20 width=1030 height=717}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nThe CSV files and figure for station 9436001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9436001/large_flood_peak_9436001.png\nThe CSV files and figure for station 9402001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9402001/large_flood_peak_9402001.png\nThe CSV files and figure for station 9416001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9416001/large_flood_peak_9416001.png\nThe CSV files and figure for station 9437002 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9437002/large_flood_peak_9437002.png\nThe CSV files and figure for station 9405001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9405001/large_flood_peak_9405001.png\nThe CSV files and figure for station 9420001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9420001/large_flood_peak_9420001.png\nThe CSV files and figure for station 9414001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9414001/large_flood_peak_9414001.png\nThe CSV files and figure for station 9404001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9404001/large_flood_peak_9404001.png\nThe CSV files and figure for station 9434001 has been saved in Hidroclima/Base de datos/10.Figuras_IHA/IHA anuales/9434001/large_flood_peak_9434001.png\n```\n:::\n:::\n\n\n",
    "supporting": [
      "indicadores_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}